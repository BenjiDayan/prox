{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18c67a48-7432-481b-9fc4-f5001ea32800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy: 1.22.3\n",
      "cuda availability: False\n",
      "device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-25 15:08:49.950062: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbenjidayan\u001b[0m (\u001b[33mvh-motion-pred\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/cluster/home/bdayan/prox/prox/virtual_huams_resource/notebooks_neat/wandb/run-20220525_150953-2irgul0l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/vh-motion-pred/rnn/runs/2irgul0l\" target=\"_blank\">TEST_RUN</a></strong> to <a href=\"https://wandb.ai/vh-motion-pred/rnn\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/66 [00:00<?, ?it/s]Thread SenderThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/cluster/home/bdayan/prox/venv38_open3d/lib64/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 51, in run\n",
      "    self._run()\n",
      "  File \"/cluster/home/bdayan/prox/venv38_open3d/lib64/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 102, in _run\n",
      "    self._process(record)\n",
      "  File \"/cluster/home/bdayan/prox/venv38_open3d/lib64/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 310, in _process\n",
      "    self._sm.send(record)\n",
      "  File \"/cluster/home/bdayan/prox/venv38_open3d/lib64/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 234, in send\n",
      "    send_handler(record)\n",
      "  File \"/cluster/home/bdayan/prox/venv38_open3d/lib64/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 956, in send_files\n",
      "    self._save_file(\n",
      "  File \"/cluster/home/bdayan/prox/venv38_open3d/lib64/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 950, in _save_file\n",
      "    self._dir_watcher.update_policy(fname, policy)\n",
      "  File \"/cluster/home/bdayan/prox/venv38_open3d/lib64/python3.8/site-packages/wandb/filesync/dir_watcher.py\", line 219, in update_policy\n",
      "    feh.on_modified(force=True)\n",
      "  File \"/cluster/home/bdayan/prox/venv38_open3d/lib64/python3.8/site-packages/wandb/filesync/dir_watcher.py\", line 154, in on_modified\n",
      "    if self.current_size == 0:\n",
      "  File \"/cluster/home/bdayan/prox/venv38_open3d/lib64/python3.8/site-packages/wandb/filesync/dir_watcher.py\", line 123, in current_size\n",
      "    return os.path.getsize(self.file_path)\n",
      "  File \"/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/genericpath.py\", line 50, in getsize\n",
      "    return os.stat(filename).st_size\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/cluster/home/bdayan/prox/prox/virtual_huams_resource/notebooks_neat/wandb/run-20220525_150953-2irgul0l/files/config.json'\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Internal wandb error: file data was not synced\n",
      "  0%|          | 0/66 [00:05<?, ?it/s]\n",
      "Exception in thread NetStatThr:\n",
      "Traceback (most recent call last):\n",
      "  File \"/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/cluster/apps/nss/gcc-6.3.0/python/3.8.5/x86_64/lib64/python3.8/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/cluster/home/bdayan/prox/venv38_open3d/lib64/python3.8/site-packages/wandb/sdk/wandb_run.py\", line 152, in check_network_status\n",
      "    status_response = self._interface.communicate_network_status()\n",
      "  File \"/cluster/home/bdayan/prox/venv38_open3d/lib64/python3.8/site-packages/wandb/sdk/interface/interface.py\", line 138, in communicate_network_status\n",
      "    resp = self._communicate_network_status(status)\n",
      "  File \"/cluster/home/bdayan/prox/venv38_open3d/lib64/python3.8/site-packages/wandb/sdk/interface/interface_shared.py\", line 405, in _communicate_network_status\n",
      "    resp = self._communicate(req, local=True)\n",
      "  File \"/cluster/home/bdayan/prox/venv38_open3d/lib64/python3.8/site-packages/wandb/sdk/interface/interface_shared.py\", line 226, in _communicate\n",
      "    return self._communicate_async(rec, local=local).get(timeout=timeout)\n",
      "  File \"/cluster/home/bdayan/prox/venv38_open3d/lib64/python3.8/site-packages/wandb/sdk/interface/interface_shared.py\", line 231, in _communicate_async\n",
      "    raise Exception(\"The wandb backend process has shutdown\")\n",
      "Exception: The wandb backend process has shutdown\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "The wandb backend process has shutdown",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 141>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    170\u001b[0m losses_rep\u001b[38;5;241m.\u001b[39mappend(loss_rep\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m    172\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m--> 174\u001b[0m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMSEloss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrep_pred_MSEloss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_rep\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m pbar\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavg last 20 loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(losses[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m20\u001b[39m:])\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m avg last 200-100: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(losses[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m200\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m])\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    178\u001b[0m writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m'\u001b[39m, losses[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], idx_counter)\n",
      "File \u001b[0;32m~/prox/venv38_open3d/lib64/python3.8/site-packages/wandb/sdk/wandb_run.py:256\u001b[0m, in \u001b[0;36m_run_decorator._noop.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    253\u001b[0m         wandb\u001b[38;5;241m.\u001b[39mtermwarn(message, repeat\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mDummy()\n\u001b[0;32m--> 256\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/prox/venv38_open3d/lib64/python3.8/site-packages/wandb/sdk/wandb_run.py:222\u001b[0m, in \u001b[0;36m_run_decorator._attach.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_is_attaching \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/prox/venv38_open3d/lib64/python3.8/site-packages/wandb/sdk/wandb_run.py:1548\u001b[0m, in \u001b[0;36mRun.log\u001b[0;34m(self, data, step, commit, sync)\u001b[0m\n\u001b[1;32m   1541\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sync \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1542\u001b[0m     deprecate\u001b[38;5;241m.\u001b[39mdeprecate(\n\u001b[1;32m   1543\u001b[0m         field_name\u001b[38;5;241m=\u001b[39mdeprecate\u001b[38;5;241m.\u001b[39mDeprecated\u001b[38;5;241m.\u001b[39mrun__log_sync,\n\u001b[1;32m   1544\u001b[0m         warning_message\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1545\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`sync` argument is deprecated and does not affect the behaviour of `wandb.log`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1546\u001b[0m         ),\n\u001b[1;32m   1547\u001b[0m     )\n\u001b[0;32m-> 1548\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcommit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/prox/venv38_open3d/lib64/python3.8/site-packages/wandb/sdk/wandb_run.py:1339\u001b[0m, in \u001b[0;36mRun._log\u001b[0;34m(self, data, step, commit)\u001b[0m\n\u001b[1;32m   1336\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mkeys()):\n\u001b[1;32m   1337\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey values passed to `wandb.log` must be strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1339\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_partial_history_callback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcommit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1341\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1342\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mgetpid() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_pid \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_attached:\n",
      "File \u001b[0;32m~/prox/venv38_open3d/lib64/python3.8/site-packages/wandb/sdk/wandb_run.py:1228\u001b[0m, in \u001b[0;36mRun._partial_history_callback\u001b[0;34m(self, row, step, commit)\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39minterface:\n\u001b[1;32m   1226\u001b[0m     not_using_tensorboard \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(wandb\u001b[38;5;241m.\u001b[39mpatched[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorboard\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1228\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_partial_history\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1230\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mflush\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpublish_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnot_using_tensorboard\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1234\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/prox/venv38_open3d/lib64/python3.8/site-packages/wandb/sdk/interface/interface.py:553\u001b[0m, in \u001b[0;36mInterfaceBase.publish_partial_history\u001b[0;34m(self, data, user_step, step, flush, publish_step, run)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flush \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    552\u001b[0m     partial_history\u001b[38;5;241m.\u001b[39maction\u001b[38;5;241m.\u001b[39mflush \u001b[38;5;241m=\u001b[39m flush\n\u001b[0;32m--> 553\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish_partial_history\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartial_history\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/prox/venv38_open3d/lib64/python3.8/site-packages/wandb/sdk/interface/interface_shared.py:62\u001b[0m, in \u001b[0;36mInterfaceShared._publish_partial_history\u001b[0;34m(self, partial_history)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish_partial_history\u001b[39m(\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28mself\u001b[39m, partial_history: pb\u001b[38;5;241m.\u001b[39mPartialHistoryRequest\n\u001b[1;32m     60\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(partial_history\u001b[38;5;241m=\u001b[39mpartial_history)\n\u001b[0;32m---> 62\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/prox/venv38_open3d/lib64/python3.8/site-packages/wandb/sdk/interface/interface_queue.py:49\u001b[0m, in \u001b[0;36mInterfaceQueue._publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_check \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m---> 49\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe wandb backend process has shutdown\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m local:\n\u001b[1;32m     51\u001b[0m         record\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mlocal \u001b[38;5;241m=\u001b[39m local\n",
      "\u001b[0;31mException\u001b[0m: The wandb backend process has shutdown"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function _WandbInit._pause_backend at 0x2b362be6b550> (for post_run_cell):\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "The wandb backend process has shutdown",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/prox/venv38_open3d/lib64/python3.8/site-packages/backcall/backcall.py:104\u001b[0m, in \u001b[0;36mcallback_prototype.<locals>.adapt.<locals>.adapted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 kwargs\u001b[38;5;241m.\u001b[39mpop(name)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/prox/venv38_open3d/lib64/python3.8/site-packages/wandb/sdk/wandb_init.py:346\u001b[0m, in \u001b[0;36m_WandbInit._pause_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun\u001b[38;5;241m.\u001b[39mlog_code(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    345\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaved code: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, res)\n\u001b[0;32m--> 346\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/prox/venv38_open3d/lib64/python3.8/site-packages/wandb/sdk/interface/interface.py:609\u001b[0m, in \u001b[0;36mInterfaceBase.publish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpublish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    608\u001b[0m     pause \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mPauseRequest()\n\u001b[0;32m--> 609\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpause\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/prox/venv38_open3d/lib64/python3.8/site-packages/wandb/sdk/interface/interface_shared.py:279\u001b[0m, in \u001b[0;36mInterfaceShared._publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m, pause: pb\u001b[38;5;241m.\u001b[39mPauseRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    278\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(pause\u001b[38;5;241m=\u001b[39mpause)\n\u001b[0;32m--> 279\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/prox/venv38_open3d/lib64/python3.8/site-packages/wandb/sdk/interface/interface_queue.py:49\u001b[0m, in \u001b[0;36mInterfaceQueue._publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_check \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m---> 49\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe wandb backend process has shutdown\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m local:\n\u001b[1;32m     51\u001b[0m         record\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mlocal \u001b[38;5;241m=\u001b[39m local\n",
      "\u001b[0;31mException\u001b[0m: The wandb backend process has shutdown"
     ]
    }
   ],
   "source": [
    "import numpy as np # for data manipulation\n",
    "print('numpy: %s' % np.__version__) # print version\n",
    "np.random.seed(0)\n",
    "import math # to help with data reshaping of the data\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import wandb\n",
    "import json\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../../src')\n",
    "\n",
    "from pose_gru import PoseGRU_inputFC2\n",
    "from benji_prox_dataloader import *\n",
    "\n",
    "print(f'cuda availability: {torch.cuda.is_available()}')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'device: {device}')\n",
    "\n",
    "name = \"TEST_RUN\"\n",
    "\n",
    "root_dir = \"/cluster/scratch/bdayan/prox_data\"\n",
    "smplx_model_path='/cluster/home/bdayan/prox/prox/models_smplx_v1_1/models/'\n",
    "\n",
    "batch_size = 15\n",
    "in_frames=15\n",
    "pred_frames=30\n",
    "frame_jump=10\n",
    "window_overlap_factor=8\n",
    "lr=0.001\n",
    "n_iter = 300\n",
    "save_every=40\n",
    "num_workers=0\n",
    "max_loss = 5. # This is dangerous but stops ridiculous updates?\n",
    "bsub_command = 'NA'  # 'bsub -n 8 -R \"rusage[mem=16384,ngpus_excl_p=1]\" python rnn_gru_joints_worldnorm.py'\n",
    "\n",
    "wandb.config = {\n",
    "    \"learning_rate\": lr,\n",
    "    \"epochs\": n_iter,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"in_frames\": in_frames,\n",
    "    \"pred_frames\": pred_frames,\n",
    "    \"frame_jump\": frame_jump,\n",
    "    \"window_overlap_factor\": window_overlap_factor,\n",
    "    \"max_loss\": max_loss,\n",
    "    \"num_workers\": num_workers,\n",
    "    \"bsub_command\": bsub_command\n",
    "}\n",
    "\n",
    "save_folder = 'saves'\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "save_path=os.path.join(save_folder, name + '_epoch{epoch}_bn{batchnum}.pt')\n",
    "save_path.format(epoch=3, batchnum=5)\n",
    "\n",
    "pd = proxDatasetSkeleton(root_dir=root_dir + '/PROXD', in_frames=in_frames, pred_frames=pred_frames, \\\n",
    "                       output_type='raw_pkls', smplx_model_path=smplx_model_path, frame_jump=frame_jump, window_overlap_factor=window_overlap_factor, extra_prefix='joints_worldnorm.pkl')\n",
    "\n",
    "val_areas =['BasementSittingBooth', 'N3OpenArea']\n",
    "\n",
    "pd = proxDatasetSkeleton(root_dir=root_dir + '/PROXD', in_frames=in_frames, pred_frames=pred_frames, \\\n",
    "                       output_type='raw_pkls', smplx_model_path=smplx_model_path, frame_jump=frame_jump, window_overlap_factor=window_overlap_factor, extra_prefix='joints_worldnorm.pkl')\n",
    "\n",
    "pd_val = proxDatasetSkeleton(root_dir=root_dir + '/PROXD', in_frames=in_frames, pred_frames=pred_frames, \\\n",
    "                       output_type='raw_pkls', smplx_model_path=smplx_model_path, frame_jump=frame_jump, window_overlap_factor=window_overlap_factor, extra_prefix='joints_worldnorm.pkl')\n",
    "\n",
    "pd.sequences = [seq for seq in pd.sequences if not any([area in seq[0] for area in val_areas])]\n",
    "pd_val.sequences = [seq for seq in pd_val.sequences if any([area in seq[0] for area in val_areas])]\n",
    "\n",
    "\n",
    "def my_collate2(batch):\n",
    "    # I think these are still np.arrays, will become tensors later\n",
    "    \n",
    "    batch = list(filter(\n",
    "        # check that they exist and don't have nans??\n",
    "        lambda triple: (triple[1] is not None) and (triple[2] is not None),\n",
    "        batch\n",
    "    ))\n",
    "    try:\n",
    "        with torch.no_grad():  # Somehow this is necessary when num_workers > 0? Input data tensor don't want grad anyway\n",
    "            batch = [(triple[0], torch.stack(triple[1][1]).squeeze(), torch.stack(triple[2][1]).squeeze()) for triple in batch]\n",
    "    \n",
    "        batch = list(filter(\n",
    "            lambda triple: (not torch.any(torch.isnan(triple[1]))) and (not torch.any(torch.isnan(triple[2]))), batch\n",
    "        ))\n",
    "        return default_collate(batch)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'batch: {[(triple[0], triple[1].shape, triple[2].shape) for triple in batch]}')\n",
    "        print(e, e.args)\n",
    "        raise e\n",
    "        \n",
    "dataloader = DataLoader(pd, batch_size=batch_size,\n",
    "                        shuffle=True, num_workers=4, pin_memory=True, collate_fn=my_collate2)\n",
    "dataloader_val = DataLoader(pd_val, batch_size=batch_size,\n",
    "                        shuffle=True, num_workers=4, pin_memory=True, collate_fn=my_collate2)\n",
    "\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "losses = []\n",
    "losses_rep = []\n",
    "\n",
    "gru = PoseGRU_inputFC2(input_size=(25,3), n_layers=4).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(gru.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "\n",
    "# I think it's important to do this after defining config? annoying though.\n",
    "_ = wandb.init(settings=wandb.Settings(start_method=\"fork\"), project=\"rnn\", entity=\"vh-motion-pred\", name=name, config=dict(wandb.config))\n",
    "\n",
    "# Actually this doesn't work :( write manuallly\n",
    "with open('config.json', 'w') as file:\n",
    "    file.write(json.dumps(dict(wandb.config)))\n",
    "    \n",
    "wandb.save('config.json')\n",
    "os.remove('config.json')\n",
    "\n",
    "idx_counter = 0\n",
    "last_fn = None\n",
    "for epoch in range(n_iter):\n",
    "    for i, (idx, in_skels, fut_skels) in (pbar := tqdm.tqdm(enumerate(dataloader), total=len(dataloader))):\n",
    "        in_skels = in_skels.to(device)\n",
    "        # print(f'in_skels device: {in_skels.device}')\n",
    "        fut_skels = fut_skels.to(device)\n",
    "        \n",
    "        pelvis = in_skels[:, 0, 0, :].unsqueeze(1).unsqueeze(1)\n",
    "        in_skels = in_skels - pelvis\n",
    "        fut_skels = fut_skels - pelvis\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        pred_frames = fut_skels.shape[1]\n",
    "        batch_len = fut_skels.shape[0]\n",
    "        # print(f'batch_len: {batch_len}')  # maybe something's wrong but I do get about avg 13 batchlen not 15 :( crummy files?\n",
    "        \n",
    "        cur_state, pred_skels = gru.forward_prediction(in_skels, pred_len=pred_frames)\n",
    "        loss = criterion(pred_skels, fut_skels)\n",
    "        loss.backward()\n",
    "        if loss.item() < max_loss:\n",
    "            optimizer.step() \n",
    "\n",
    "        rep_pred = in_skels[:, -1, :, :]\n",
    "        a = rep_pred.detach().cpu().numpy()\n",
    "        \n",
    "        a = np.tile(a, (fut_skels.shape[1], 1, 1, 1))\n",
    "        rep_pred = torch.Tensor(a).transpose(0, 1).to(device)\n",
    "\n",
    "        loss_rep = criterion(rep_pred, fut_skels)\n",
    "        losses_rep.append(loss_rep.item())\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        wandb.log({'MSEloss': loss, 'rep_pred_MSEloss': loss_rep})\n",
    "        \n",
    "        pbar.set_description(f\"avg last 20 loss: {np.mean(losses[-20:]):.4f} avg last 200-100: {np.mean(losses[-200:-100]):.4f}\")\n",
    "\n",
    "        writer.add_scalar('Loss', losses[-1], idx_counter)\n",
    "        writer.add_scalar('Loss_rep', losses_rep[-1], idx_counter)\n",
    "        if i % save_every == (save_every-1):\n",
    "            fn = save_path.format(epoch=epoch, batchnum=i)\n",
    "            torch.save({\n",
    "            'epoch': epoch,\n",
    "            'batch_num': i,\n",
    "            'model_state_dict': gru.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            }, fn)\n",
    "            wandb.save(fn)       \n",
    "            if last_fn:\n",
    "                os.remove(last_fn)\n",
    "            last_fn = fn\n",
    "            \n",
    "        idx_counter += 1\n",
    "    print(f'end epoch {epoch}: total mean loss: {np.mean(losses)}')\n",
    "    \n",
    "    epoch_val_losses = []\n",
    "    epoch_val_replosses = []\n",
    "    for i, (idx, in_skels, fut_skels) in (pbar := tqdm.tqdm(enumerate(dataloader_val), total=len(dataloader_val))):\n",
    "        in_skels = in_skels.to(device)\n",
    "        fut_skels = fut_skels.to(device)\n",
    "        \n",
    "        pelvis = in_skels[:, 0, 0, :].unsqueeze(1).unsqueeze(1)\n",
    "        in_skels = in_skels - pelvis\n",
    "        fut_skels = fut_skels - pelvis\n",
    "\n",
    "        \n",
    "        pred_frames = fut_skels.shape[1]\n",
    "        batch_len = fut_skels.shape[0]\n",
    "        \n",
    "        cur_state, pred_skels = gru.forward_prediction(in_skels, pred_len=pred_frames)\n",
    "        \n",
    "        loss = criterion(pred_skels, fut_skels)\n",
    "\n",
    "        rep_pred = in_skels[:, -1, :, :]\n",
    "        a = rep_pred.detach().cpu().numpy()\n",
    "        a = np.tile(a, (fut_skels.shape[1], 1, 1, 1))\n",
    "        rep_pred = torch.Tensor(a).transpose(0, 1).to(device)\n",
    "        loss_rep = criterion(rep_pred, fut_skels)\n",
    "        \n",
    "        epoch_val_replosses.append(loss_rep.item())       \n",
    "        epoch_val_losses.append(loss.item())\n",
    "        \n",
    "    epoch_val_loss = np.mean(list(filter(lambda loss: loss < max_loss, epoch_val_losses)))\n",
    "    epoch_val_reploss = np.mean(list(filter(lambda loss: loss < max_loss, epoch_val_replosses)))\n",
    "    wandb.log({'epoch_val_loss': epoch_val_loss, 'epoch_val_reploss': epoch_val_reploss})\n",
    "    \n",
    "\n",
    "plt.plot(losses)\n",
    "print(losses[-4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5ababb7-05d4-40a9-825b-078985dc2246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.config\n",
    "\n",
    "_ = wandb.init(settings=wandb.Settings(start_method=\"fork\"), project=\"rnn\", entity=\"vh-motion-pred\", name=name, config=wandb.config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e03e22b-1bfa-47c7-a601-4eb32a93a612",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.config = {\n",
    "    \"learning_rate\": lr,\n",
    "    \"epochs\": n_iter,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"in_frames\": in_frames,\n",
    "    \"pred_frames\": pred_frames,\n",
    "    \"frame_jump\": frame_jump,\n",
    "    \"window_overlap_factor\": window_overlap_factor,\n",
    "    \"max_loss\": max_loss,\n",
    "    \"num_workers\": num_workers,\n",
    "    \"bsub_command\": bsub_command\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4db8b3fd-728e-4b37-919a-bc91c9f16258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.001,\n",
       " 'epochs': 300,\n",
       " 'batch_size': 15,\n",
       " 'in_frames': 15,\n",
       " 'pred_frames': 30,\n",
       " 'frame_jump': 10,\n",
       " 'window_overlap_factor': 8,\n",
       " 'max_loss': 5.0,\n",
       " 'num_workers': 0,\n",
       " 'bsub_command': 'NA'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(wandb.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c2c18e-9a64-4baf-a6c9-ac75fd47442b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
