{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import glob\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import cv2\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "from projection_utils import Projection\n",
    "from data_parser import read_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# _____________ read frames _____________\n",
    "data_root = '../quantitative/recordings'\n",
    "sequence_id = 'vicon_03301_01'\n",
    "save_root = '../quantitative/proximity'\n",
    "\n",
    "rgb_list = glob.glob(os.path.join(data_root, sequence_id, 'Color/*.jpg'))\n",
    "rgb_list.sort()\n",
    "# rgb_list[-1][-33:-30]\n",
    "n_frame = int(rgb_list[-1][-33:-30])  # total frame number\n",
    "# rgb_list\n",
    "n_frame\n",
    "# rgb_list[-1][-34:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _____________ init _____________\n",
    "projection = Projection(\"../quantitative/calibration\")\n",
    "MAX_DEPTH = 20.0\n",
    "depth_scale = 1e3       # TODO: determine depth_scale\n",
    "point_cloud = o3d.geometry.PointCloud()\n",
    "vis = o3d.visualization.Visualizer()\n",
    "h = 1080\n",
    "w = 1920\n",
    "\n",
    "curr_frame = rgb_list[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4825, 3)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# _____________ make 3d point cloud _____________\n",
    "# for curr_frame in rgb_list:\n",
    "mask = cv2.imread(os.path.join(data_root, sequence_id, 'BodyIndexColor/' + curr_frame[-34:-4] + '.png'), cv2.IMREAD_GRAYSCALE)\n",
    "nomask = mask == 255\n",
    "depth_im = cv2.imread(os.path.join(data_root, sequence_id, 'Depth/' + curr_frame[-34:-4] + '.png'), flags=-1).astype(float)\n",
    "depth_im = depth_im / 8.\n",
    "depth_im = depth_im * depth_scale\n",
    "scan_dict = projection.create_scan(nomask, depth_im, mask_on_color = True)        # points & colors\n",
    "point_cloud.points.extend(scan_dict.get('points'))\n",
    "point_cloud.colors.extend(scan_dict.get('colors'))\n",
    "# np.asarray(point_cloud.points).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\u001b[1;31m[Open3D Error] (static std::shared_ptr<RGBDImage> open3d::geometry::RGBDImage::CreateFromColorAndDepth(const open3d::geometry::Image &, const open3d::geometry::Image &, double, double, bool)) /Users/runner/work/Open3D/Open3D/cpp/open3d/geometry/RGBDImageFactory.cpp:42: [CreateFromColorAndDepth] Unsupported image format.\n\u001b[0;m",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/guangzhu/Desktop/ETHz/S2/VH/project/prox/src/explore_data.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/guangzhu/Desktop/ETHz/S2/VH/project/prox/src/explore_data.ipynb#ch0000029?line=0'>1</a>\u001b[0m \u001b[39m################### get scene point could of cur_frame_N ###################\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/guangzhu/Desktop/ETHz/S2/VH/project/prox/src/explore_data.ipynb#ch0000029?line=1'>2</a>\u001b[0m rgb_im \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(curr_frame)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/guangzhu/Desktop/ETHz/S2/VH/project/prox/src/explore_data.ipynb#ch0000029?line=2'>3</a>\u001b[0m rgbd_image \u001b[39m=\u001b[39m o3d\u001b[39m.\u001b[39;49mgeometry\u001b[39m.\u001b[39;49mRGBDImage\u001b[39m.\u001b[39;49mcreate_from_color_and_depth(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/guangzhu/Desktop/ETHz/S2/VH/project/prox/src/explore_data.ipynb#ch0000029?line=3'>4</a>\u001b[0m     o3d\u001b[39m.\u001b[39;49mgeometry\u001b[39m.\u001b[39;49mImage((np\u001b[39m.\u001b[39;49masarray(rgb_im))\u001b[39m.\u001b[39;49mastype(np\u001b[39m.\u001b[39;49muint8)),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/guangzhu/Desktop/ETHz/S2/VH/project/prox/src/explore_data.ipynb#ch0000029?line=4'>5</a>\u001b[0m     o3d\u001b[39m.\u001b[39;49mgeometry\u001b[39m.\u001b[39;49mImage(np\u001b[39m.\u001b[39;49masarray(depth_im\u001b[39m.\u001b[39;49mastype(np\u001b[39m.\u001b[39;49mfloat32))),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/guangzhu/Desktop/ETHz/S2/VH/project/prox/src/explore_data.ipynb#ch0000029?line=5'>6</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/guangzhu/Desktop/ETHz/S2/VH/project/prox/src/explore_data.ipynb#ch0000029?line=6'>7</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m../quantitative/calibration/IR.json\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/guangzhu/Desktop/ETHz/S2/VH/project/prox/src/explore_data.ipynb#ch0000029?line=7'>8</a>\u001b[0m         camera_ir \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f) \n",
      "\u001b[0;31mRuntimeError\u001b[0m: \u001b[1;31m[Open3D Error] (static std::shared_ptr<RGBDImage> open3d::geometry::RGBDImage::CreateFromColorAndDepth(const open3d::geometry::Image &, const open3d::geometry::Image &, double, double, bool)) /Users/runner/work/Open3D/Open3D/cpp/open3d/geometry/RGBDImageFactory.cpp:42: [CreateFromColorAndDepth] Unsupported image format.\n\u001b[0;m"
     ]
    }
   ],
   "source": [
    "################### get scene point could of cur_frame_N ###################\n",
    "rgb_im = cv2.imread(curr_frame)\n",
    "rgb_im = rgb_im[:, :, ::-1]\n",
    "rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "    o3d.geometry.Image((np.asarray(rgb_im)).astype(np.uint8)),\n",
    "    o3d.geometry.Image(np.asarray(depth_im.astype(np.float32))),\n",
    ")\n",
    "with open('../quantitative/calibration/IR.json') as f:\n",
    "        camera_ir = json.load(f) \n",
    "pcd = o3d.geometry.PointCloud.create_from_rgbd_image(\n",
    "    rgbd_image,\n",
    "    o3d.camera.PinholeCameraIntrinsic(w, h, camera_ir['f'][0], camera_ir['f'][1], camera_ir['c'][0], camera_ir['c'][1]),\n",
    ")  # cam coordinate\n",
    "\n",
    "scene_verts = np.asarray(pcd.points)     # [h*w, 3], coordinate of each pixel in the depth map\n",
    "scene_verts_aug = np.hstack([scene_verts, np.ones([scene_verts.shape[0], 1])])\n",
    "with open('../quantitative/cam2world/vicon.json') as f:\n",
    "        camera_ext = json.load(f)\n",
    "cam_extr_ref = np.linalg.inv(camera_ext)\n",
    "scene_verts = scene_verts_aug.dot(cam_extr_ref)[:, :3]      # camera to world transformation\n",
    "pcd.points = o3d.utility.Vector3dVector(scene_verts) # world coordinate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1920"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# _____________ read keypoints and skeleton _____________\n",
    "keyp_tuple = read_keypoints('../quantitative/keypoints/' + sequence_id + '/' + rgb_list[5][-34:-4] + '_keypoints.json', use_hands=False, use_face=False, use_face_contour=False)\n",
    "keypoints = np.stack(keyp_tuple.keypoints)\n",
    "keypoints.shape\n",
    "# mask.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'transl': array([[-0.6994415 , -0.31427762,  0.9848179 ]], dtype=float32),\n",
       " 'num_pca_comps': 12,\n",
       " 'beta': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " 'jaw_pose': array([[0., 0., 0.]], dtype=float32),\n",
       " 'body_pose': array([[ 0.0590809 ,  0.05310533,  0.09144919,  0.06638564, -0.03938352,\n",
       "         -0.03405466,  0.04605372,  0.03528766, -0.00767644, -0.01093746,\n",
       "         -0.04850643, -0.04170513, -0.00294363,  0.09496448,  0.04342466,\n",
       "          0.04438157, -0.05772606,  0.02723523,  0.02083636,  0.204744  ,\n",
       "         -0.04182123,  0.00783336, -0.13903025,  0.09834542,  0.03948856,\n",
       "         -0.01690864,  0.0097099 ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.11294897,  0.02547551,\n",
       "          0.01097451,  0.05551571, -0.02713786, -0.38216677,  0.06716956,\n",
       "          0.01517425,  0.40331653,  0.11045438, -0.00737314,  0.05088175,\n",
       "          0.0304325 , -0.12942097, -0.5711655 ,  0.06874575,  0.0668682 ,\n",
       "          0.5659935 ,  0.0295037 , -0.30085886, -0.01249242, -0.05512818,\n",
       "          0.4115289 , -0.15507044, -0.08258306, -0.15217505,  0.04894594,\n",
       "         -0.1401711 ,  0.07769895,  0.00864173]], dtype=float32),\n",
       " 'right_hand_pose': array([[ 1.1544436 ,  0.11370432, -0.02424388, -0.06176253,  0.726522  ,\n",
       "          0.07428434,  1.1343087 , -0.22562979,  0.2852789 , -0.40444565,\n",
       "         -0.0683852 , -0.17769055]], dtype=float32),\n",
       " 'left_hand_pose': array([[ 1.299731  ,  0.1638163 ,  0.6141253 ,  0.46374097,  0.8784018 ,\n",
       "         -0.00959849,  0.5971352 , -0.57580954,  0.0547456 , -0.5481908 ,\n",
       "          0.6514663 , -0.09600541]], dtype=float32),\n",
       " 'global_orient': array([[ 1.4545091, -0.3872004, -0.4530339]], dtype=float32)}"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# _____________ read keypoints and skeleton (pickle) _____________\n",
    "path = \"../quantitative/fittings/mosh/vicon_03301_01/results/s001_frame_00001__00.00.00.023/000.pkl\"\n",
    "with open(path, 'rb') as file:\n",
    "    smpl = pickle.load(file, encoding='latin1')\n",
    "smpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "smplx_model_path='../models_smplx_v1_1/models/smplx/SMPLX_NEUTRAL2.pkl'\n",
    "with open(smplx_model_path, 'rb') as file:\n",
    "    out = pickle.load(file, encoding='latini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "smplx_model_path='../models_smplx_v1_1/models/smplx/SMPLX_NEUTRAL2.pkl'\n",
    "with open(smplx_model_path, 'wb') as file:\n",
    "    pickle.dump(out, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- pytorch version=1.10.2\n",
      "-- device=cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# specify device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "\n",
    "print('-- pytorch version={}'.format(torch.__version__))\n",
    "print('-- device={}'.format(device))\n",
    "\n",
    "smplx_model_path='../models_smplx_v1_1/models/smplx/SMPLX_NEUTRAL2.pkl'\n",
    "\n",
    "import smplx  # SMPL-X; pip install smplx\n",
    "\n",
    "def get_smplx_model(gender, device):\n",
    "    body_model_path = smplx_model_path\n",
    "    body_model = smplx.create(body_model_path, \n",
    "                          model_type='smplx',        ## smpl, smpl+h, or smplx?\n",
    "                          gender=gender, ext='npz',  ## file format \n",
    "                          num_pca_comps=12,          ## MANO hand pose pca component\n",
    "                          create_global_orient=True, \n",
    "                          create_body_pose=True,\n",
    "                          create_betas=True,\n",
    "                          create_left_hand_pose=True,\n",
    "                          create_right_hand_pose=True,\n",
    "                          create_expression=True, \n",
    "                          create_jaw_pose=True,\n",
    "                          create_leye_pose=True,\n",
    "                          create_reye_pose=True,\n",
    "                          create_transl=True,\n",
    "                          batch_size=1               ## how many bodies in a batch?\n",
    "                          )\n",
    "    body_model.eval()\n",
    "    return body_model\n",
    "\n",
    "smplx_neutral = get_smplx_model(gender='neutral', device=device)\n",
    "\n",
    "\n",
    "def draw_bodies(gender, betas, thetas):\n",
    "    bm = smplx_neutral\n",
    "\n",
    "\n",
    "    ## read verts and face from smplx model\n",
    "    params = {'betas': betas,\n",
    "              'body_pose': thetas\n",
    "              }\n",
    "\n",
    "\n",
    "    verts = bm(return_verts=True, **params).vertices.detach().cpu().numpy()[0]\n",
    "    faces = bm.faces\n",
    "\n",
    "    ## put verts and face into open3d, and compute surface normal\n",
    "    coord = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.5)\n",
    "    body = o3d.geometry.TriangleMesh()\n",
    "    body.vertices = o3d.utility.Vector3dVector(verts)\n",
    "    body.triangles = o3d.utility.Vector3iVector(faces)\n",
    "    body.vertex_normals = o3d.utility.Vector3dVector([])\n",
    "    body.triangle_normals = o3d.utility.Vector3dVector([])\n",
    "    body.compute_vertex_normals()\n",
    "    o3d.visualization.draw_geometries([body, coord])\n",
    "    \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = smpl\n",
    "betas = torch.Tensor(data['beta']).reshape(1, -1)\n",
    "body_pose = torch.Tensor(data['body_pose'])\n",
    "global_orient= torch.Tensor(data['global_orient'])\n",
    "transl=torch.Tensor(data['transl'])\n",
    "out = smplx_neutral(return_joints=True, betas=betas, body_pose=body_pose, global_orient=global_orient, transl=transl)\n",
    "joints = out.joints[:, :21].squeeze()\n",
    "joint_locations = (joints)\n",
    "body_joints_3d = (out.vertices.detach().cpu().numpy().squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.64845455, -0.6978891 ,  1.6229868 ],\n",
       "       [-0.6453289 , -0.70073915,  1.6220896 ],\n",
       "       [-0.64521587, -0.701429  ,  1.6235468 ],\n",
       "       ...,\n",
       "       [-0.7683206 , -0.69977   ,  1.63098   ],\n",
       "       [-0.7660532 , -0.7000109 ,  1.6318812 ],\n",
       "       [-0.76385707, -0.70072234,  1.6327178 ]], dtype=float32)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body_joints_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIMBS = [\n",
    "(0, 1),  # head_center -> neck\n",
    "(1, 2),  # neck -> right_clavicle\n",
    "(2, 3),  # right_clavicle -> right_shoulder\n",
    "(3, 4),  # right_shoulder -> right_elbow\n",
    "(4, 5),  # right_elbow -> right_wrist\n",
    "(1, 6),  # neck -> left_clavicle\n",
    "(6, 7),  # left_clavicle -> left_shoulder\n",
    "(7, 8),  # left_shoulder -> left_elbow\n",
    "(8, 9),  # left_elbow -> left_wrist\n",
    "(1, 10),  # neck -> spine0\n",
    "(10, 11),  # spine0 -> spine1\n",
    "(11, 12),  # spine1 -> spine2\n",
    "(12, 13),  # spine2 -> spine3\n",
    "(13, 14),  # spine3 -> spine4\n",
    "(14, 15),  # spine4 -> right_hip\n",
    "(15, 16),  # right_hip -> right_knee\n",
    "(16, 17),  # right_knee -> right_ankle\n",
    "(14, 18),  # spine4 -> left_hip\n",
    "(18, 19),  # left_hip -> left_knee\n",
    "(19, 20),  # left_knee -> left_ankle\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48497,)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = body_joints_3d[np.asarray(LIMBS)[:, 0]]  # [n_limb, 3]\n",
    "B = body_joints_3d[np.asarray(LIMBS)[:, 1]]  # [n_limb, 3]\n",
    "n_pt = np.asarray(point_cloud.points).shape[0]\n",
    "n_limb = A.shape[0]\n",
    "\n",
    "A = np.tile(A, (n_pt, 1)).reshape(n_pt*n_limb, 3)  # [n_pt, n_limb, 3], n_pt=n_bps=scene_verts.shape[0]\n",
    "B = np.tile(B, (n_pt, 1)).reshape(n_pt*n_limb, 3)\n",
    "P = np.tile(np.asarray(point_cloud.points), n_limb).reshape(n_pt*n_limb, 3)\n",
    "\n",
    "AB = B - A\n",
    "AP = P - A\n",
    "BP = P - B\n",
    "\n",
    "temp_1 = np.multiply(AB, AP).sum(axis=-1)  # [n_pt, n_limb]\n",
    "temp_2 = np.multiply(-AB, BP).sum(axis=-1)  # [n_pt, n_limb]\n",
    "mask_1 = np.where(temp_1 <= 0)[0]   # angle between AB and AP >= 90\n",
    "mask_2 = np.where((temp_1 > 0) * (temp_2 <= 0))[0]  # angle between AB and AP < 90 and angle between BA and BP >= 90\n",
    "mask_3 = np.where((temp_1 > 0) * (temp_2 > 0))[0]   # angle between AB and AP < 90 and angle between BA and BP < 90\n",
    "if len(mask_1) + len(mask_2) + len(mask_3) != n_pt*n_limb:\n",
    "    print('[distance calculation] num of verts does not match!')\n",
    "\n",
    "dist_1 = np.sqrt(np.sum((P[mask_1]-A[mask_1])**2, axis=-1))  # [n_mask_1]\n",
    "dist_2 = np.sqrt(np.sum((P[mask_2]-B[mask_2])**2, axis=-1))  # [n_mask_2]\n",
    "\n",
    "x = np.multiply(AB[mask_3], AP[mask_3]).sum(axis=-1) / np.multiply(AB[mask_3], AB[mask_3]).sum(axis=-1)  # [n_mask_3]\n",
    "x = x.repeat(3).reshape(-1,3)\n",
    "C = x * AB[mask_3] + A[mask_3]  # C: [n_mask_3, 3], the projected point of P on line segment AB\n",
    "dist_3 = np.sqrt(np.sum((P[mask_3]-C)**2, axis=-1))  # n_mask_3\n",
    "\n",
    "dist = np.zeros(n_pt*n_limb)\n",
    "dist[mask_1] = dist_1\n",
    "dist[mask_2] = dist_2\n",
    "dist[mask_3] = dist_3\n",
    "dist = dist.reshape(n_pt, n_limb)  # [n_pt, n_limb], distance from each point in scene verts to each limb\n",
    "body_bps = np.min(dist, axis=-1)   # [n_pt]\n",
    "body_bps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2073600"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_frame = rgb_list[5]\n",
    "mask = cv2.imread(os.path.join(data_root, sequence_id, 'BodyIndexColor/' + curr_frame[-34:-4] + '.png'), cv2.IMREAD_GRAYSCALE)\n",
    "h = mask.shape[0]\n",
    "w = mask.shape[1]\n",
    "mask = mask.reshape(h*w)\n",
    "# mask\n",
    "h*w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2025784,)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "nomask = (mask == 255)\n",
    "mask = nomask == False\n",
    "mask_ind = np.where(mask == True)[0]\n",
    "nomask_ind = np.asarray(list(set(range(h*w))-set(mask_ind))).astype(int)\n",
    "# mask_ind.shape\n",
    "nomask_ind.shape\n",
    "# mask_ind\n",
    "# body_bps_full = np.zeros([h * w])\n",
    "# body_bps_full[nomask_ind]\n",
    "# body_bps_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shape mismatch: value array of shape (48497,) could not be broadcast to indexing result of shape (2025784,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/guangzhu/Desktop/ETHz/S2/VH/project/prox/src/explore_data.ipynb Cell 16'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/guangzhu/Desktop/ETHz/S2/VH/project/prox/src/explore_data.ipynb#ch0000028?line=0'>1</a>\u001b[0m \u001b[39m########### back to image plane, visualize bps feature map ###########\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/guangzhu/Desktop/ETHz/S2/VH/project/prox/src/explore_data.ipynb#ch0000028?line=1'>2</a>\u001b[0m \u001b[39m# print(cur_frame, cur_frame_N)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/guangzhu/Desktop/ETHz/S2/VH/project/prox/src/explore_data.ipynb#ch0000028?line=2'>3</a>\u001b[0m body_bps_full[nomask_ind] \u001b[39m=\u001b[39m body_bps\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/guangzhu/Desktop/ETHz/S2/VH/project/prox/src/explore_data.ipynb#ch0000028?line=3'>4</a>\u001b[0m body_bps_full[mask_ind] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m         \u001b[39m# set masked pixels to 0\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/guangzhu/Desktop/ETHz/S2/VH/project/prox/src/explore_data.ipynb#ch0000028?line=4'>5</a>\u001b[0m body_bps_full \u001b[39m=\u001b[39m body_bps_full\u001b[39m.\u001b[39mreshape((h, w))  \u001b[39m# body bps feature map, [h, w]\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: shape mismatch: value array of shape (48497,) could not be broadcast to indexing result of shape (2025784,)"
     ]
    }
   ],
   "source": [
    "########### back to image plane, visualize bps feature map ###########\n",
    "# print(cur_frame, cur_frame_N)\n",
    "body_bps_full[nomask_ind] = body_bps\n",
    "body_bps_full[mask_ind] = 0         # set masked pixels to 0\n",
    "body_bps_full = body_bps_full.reshape((h, w))  # body bps feature map, [h, w]\n",
    "body_bps_full = body_bps_full.astype(np.float32)\n",
    "np.save('{}/seq_{:04d}_fr_{:05d}.npy'.format(save_root, '/proximity/', curr_frame[-34:-4]), body_bps_full)\n",
    "\n",
    "plt.imshow(body_bps_full, cmap='plasma')\n",
    "plt.show()\n",
    "\n",
    "body_bps_full[body_bps_full>10] = 10\n",
    "fig = plt.imshow(body_bps_full, cmap='plasma', vmin=0, vmax=5)\n",
    "plt.axis('off')\n",
    "fig.axes.get_xaxis().set_visible(False)\n",
    "fig.axes.get_yaxis().set_visible(False)\n",
    "plt.imsave('{}/seq_{:04d}_fr_{:05d}.png'.format(save_root, '/proximity', curr_frame[-34:-4]), body_bps_full, cmap='plasma')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ef0bfd5a0a44da5bab5ff7f08d2a6c1e67915635db3105f67f5f1f3a2b92236c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
