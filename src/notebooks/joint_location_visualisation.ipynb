{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7483b843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy: 1.21.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np # for data manipulation\n",
    "print('numpy: %s' % np.__version__) # print version\n",
    "import math # to help with data reshaping of the data\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "#import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import os\n",
    "os.chdir('../')\n",
    "\n",
    "from pose_gru import PoseGRU_inputFC2\n",
    "from benji_prox_dataloader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8408fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"D:/prox_data/joint_locations/\"\n",
    "# root_dir = \"/cluster/scratch/bdayan/prox_data/joint_locations/\"\n",
    "\n",
    "batch_size = 15\n",
    "\n",
    "pd = proxDatasetJoints(root_dir)\n",
    "dataloader = DataLoader(pd, batch_size=batch_size,\n",
    "                        shuffle=True, num_workers=0, collate_fn=my_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dedc009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_epoch0_bn391.pt',\n",
       " 'model_epoch1_bn391.pt',\n",
       " 'model_epoch2_bn391.pt',\n",
       " 'model_epoch3_bn391.pt',\n",
       " 'model_epoch4_bn391.pt',\n",
       " 'model_epoch5_bn391.pt',\n",
       " 'model_epoch6_bn391.pt',\n",
       " 'model_epoch7_bn391.pt',\n",
       " 'model_epoch8_bn391.pt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('model_saves')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b1457b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = torch.load('model_saves/model_epoch0_bn391.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "692b48c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch': 0,\n",
       " 'batch_num': 391,\n",
       " 'model_state_dict': OrderedDict([('input_fc.weight',\n",
       "               tensor([[-0.0778, -0.0539, -0.1031,  ...,  0.0457, -0.1046,  0.0689],\n",
       "                       [ 0.0752,  0.1063, -0.0152,  ...,  0.0983,  0.0975,  0.0616],\n",
       "                       [ 0.0906, -0.1042,  0.0630,  ...,  0.0733,  0.0256, -0.0575],\n",
       "                       ...,\n",
       "                       [-0.0036, -0.0701, -0.1068,  ...,  0.0971,  0.0305,  0.0513],\n",
       "                       [-0.0931,  0.0694,  0.0517,  ...,  0.0021, -0.0607,  0.0622],\n",
       "                       [-0.0267,  0.0743,  0.0418,  ..., -0.0525, -0.0583,  0.0038]])),\n",
       "              ('input_fc.bias',\n",
       "               tensor([-7.7283e-02,  5.6047e-02,  8.1545e-02, -4.4304e-02, -8.1215e-02,\n",
       "                        7.6695e-02, -6.9363e-02, -1.0661e-01,  2.1687e-02,  8.9244e-02,\n",
       "                        5.2472e-03,  3.4373e-02, -3.9705e-02, -3.7916e-02, -1.1000e-01,\n",
       "                       -1.0352e-01,  5.1028e-02,  3.5083e-02, -8.0592e-02,  1.1334e-01,\n",
       "                        7.3194e-03,  1.3057e-02, -2.0489e-03,  2.5495e-02,  2.0417e-02,\n",
       "                        9.6639e-02, -6.1366e-02,  1.1575e-01, -3.1437e-02,  8.8551e-02,\n",
       "                       -1.1921e-02, -9.0050e-02,  6.8995e-02,  1.1386e-01,  7.1555e-02,\n",
       "                       -5.0081e-02, -4.1248e-02, -1.1382e-01, -4.9095e-02, -1.1729e-02,\n",
       "                       -9.0570e-02,  9.7821e-02,  2.7940e-02, -5.3262e-02, -5.6196e-02,\n",
       "                       -7.3362e-02,  8.2044e-02, -1.0232e-01, -7.4362e-02, -1.0913e-01,\n",
       "                       -9.6539e-02, -4.0645e-02,  4.5880e-02,  8.7401e-03, -1.1688e-01,\n",
       "                       -8.1798e-02,  1.1021e-01,  8.1437e-02, -9.4064e-02,  3.5037e-02,\n",
       "                        4.2677e-02,  3.2869e-02, -2.2736e-02, -7.4660e-02, -6.3169e-03,\n",
       "                       -1.9575e-03, -6.2683e-03, -1.6972e-02,  1.0775e-01,  1.1158e-01,\n",
       "                       -9.2790e-02,  4.7321e-02, -4.4215e-02,  9.6088e-02, -8.0021e-02,\n",
       "                       -8.8521e-02,  7.3488e-03, -8.3049e-02,  2.4052e-02, -7.0302e-02,\n",
       "                        4.1403e-02, -3.4218e-02, -2.9977e-02, -5.6694e-02, -4.8772e-02,\n",
       "                        3.0470e-02, -3.3966e-02,  1.0559e-01, -6.2938e-03,  5.8371e-02,\n",
       "                       -8.7383e-02, -5.4554e-02,  4.0115e-02, -2.6741e-02, -1.1916e-02,\n",
       "                       -9.2861e-02,  7.3311e-02,  1.1063e-01,  2.0557e-02, -8.8956e-02,\n",
       "                       -7.7733e-02,  9.8803e-02, -4.6424e-02, -1.1430e-01, -1.2746e-02,\n",
       "                       -5.7914e-02, -1.7322e-03, -7.6302e-02,  5.0099e-02, -7.6257e-02,\n",
       "                        2.5903e-02, -4.6256e-02, -2.0248e-02,  7.1091e-02, -5.9300e-02,\n",
       "                       -3.2613e-02,  9.6559e-02,  9.8566e-02,  6.5957e-02,  1.1434e-01,\n",
       "                        4.4790e-02, -3.0247e-02,  1.7790e-02, -3.7905e-02,  1.8837e-02,\n",
       "                       -6.0137e-02, -2.5835e-02,  8.4378e-02,  5.0678e-02,  1.7371e-02,\n",
       "                       -2.5879e-02, -2.0915e-02, -4.3919e-02, -8.7929e-02,  1.0501e-01,\n",
       "                        4.9438e-02,  1.0989e-03,  8.0590e-02, -7.8216e-02, -2.8932e-02,\n",
       "                       -2.6677e-02,  4.9474e-02, -7.5420e-02, -1.1297e-01, -6.2175e-02,\n",
       "                       -4.6553e-02,  5.8695e-02,  7.2837e-02, -3.0992e-02, -3.7350e-02,\n",
       "                        1.0459e-02,  1.9462e-02,  8.3588e-03, -1.0242e-01,  1.0152e-02,\n",
       "                       -4.0800e-02, -1.9261e-02, -1.6481e-02, -2.6864e-02,  2.0313e-02,\n",
       "                       -7.7811e-02,  3.8973e-02, -5.2526e-02,  9.6922e-02, -7.9931e-02,\n",
       "                        8.3107e-02, -9.4873e-02, -5.1752e-02,  1.1167e-01,  6.6470e-02,\n",
       "                       -7.9427e-02,  1.1714e-02, -9.5853e-02, -8.5952e-03, -4.3222e-02,\n",
       "                       -3.8391e-02,  3.6338e-02,  8.8411e-02, -1.0619e-01, -6.6042e-02,\n",
       "                        2.3325e-02, -2.5990e-02,  4.7621e-02,  9.9267e-02, -8.8084e-02,\n",
       "                        8.3227e-02,  1.8342e-02, -5.9200e-02,  3.1982e-02, -9.6417e-03,\n",
       "                       -5.9373e-02, -1.9077e-02, -8.1058e-02,  1.1277e-01, -4.2982e-02,\n",
       "                        1.0276e-01, -7.3572e-02, -7.0327e-02,  2.8448e-02,  2.1341e-02,\n",
       "                       -4.0019e-02, -1.8750e-02,  7.9425e-02, -8.9493e-03,  3.9512e-02,\n",
       "                       -6.3039e-02, -3.8703e-02, -7.3377e-02,  3.2010e-02,  4.6926e-02,\n",
       "                       -2.1643e-02, -6.0334e-02, -1.0933e-01,  2.0126e-02,  3.8469e-02,\n",
       "                        9.0891e-02,  1.1041e-01,  3.5806e-02,  2.4709e-02, -7.1159e-03,\n",
       "                       -3.5932e-02, -2.9883e-03,  1.1325e-01, -3.9232e-02,  6.3385e-02,\n",
       "                       -7.6869e-02,  4.2767e-02, -9.7306e-02,  4.0457e-02,  1.1624e-01,\n",
       "                        8.8690e-02, -2.4755e-02,  2.2373e-02,  4.3508e-02, -3.0440e-02,\n",
       "                        5.5460e-03, -4.4863e-02,  8.3118e-02,  1.8141e-02,  4.9002e-03,\n",
       "                        1.0462e-01,  5.0579e-02,  3.3100e-02, -3.8206e-02, -6.9779e-02,\n",
       "                        1.0523e-01,  9.5069e-02,  5.0079e-02, -8.2646e-02, -1.1623e-01,\n",
       "                        5.8651e-02,  7.2832e-02,  6.9007e-02,  7.4068e-02,  7.2106e-02,\n",
       "                        9.7736e-02, -1.0228e-01, -1.0696e-01,  4.9256e-02, -3.0559e-02,\n",
       "                        8.4313e-02, -5.9678e-02, -1.1439e-01,  1.1407e-01,  4.4707e-02,\n",
       "                       -8.9766e-02,  9.6057e-03, -7.7584e-02,  5.9020e-04,  4.4173e-03,\n",
       "                       -1.2813e-02, -8.3416e-02,  5.1169e-02, -9.3257e-02,  1.8271e-02,\n",
       "                       -7.5021e-02,  6.6143e-02,  9.5868e-02,  1.3644e-02,  2.4358e-02,\n",
       "                       -4.7265e-02, -3.1300e-02,  1.0716e-01, -6.4464e-03, -1.4392e-02,\n",
       "                        1.1230e-01, -7.8152e-02, -1.2571e-02,  4.3739e-02, -1.9402e-03,\n",
       "                       -6.3508e-03, -8.3117e-02,  7.0639e-02, -1.1195e-01,  1.0872e-01,\n",
       "                       -3.7444e-03, -7.6149e-02, -5.0237e-02,  6.3683e-02, -6.7261e-03,\n",
       "                        4.2291e-02,  8.2484e-02, -2.6738e-02, -3.2585e-02,  1.7757e-02,\n",
       "                       -9.8171e-02, -3.8692e-02, -8.8899e-02,  5.0223e-02,  7.6658e-02,\n",
       "                        1.0452e-01, -1.0844e-01, -3.1351e-02,  1.7801e-02,  1.3892e-02,\n",
       "                       -2.0953e-03, -6.2176e-02, -1.0606e-01, -5.8307e-02, -7.8784e-02,\n",
       "                        4.3384e-03, -2.4009e-02,  5.4274e-02,  2.1845e-02, -1.1224e-01,\n",
       "                       -5.4319e-03, -3.5865e-02, -2.9388e-02,  1.0583e-01,  2.8956e-02,\n",
       "                        7.3838e-02,  1.1148e-01, -8.8268e-02,  7.0909e-02,  2.4482e-02,\n",
       "                        1.0792e-01,  9.6855e-02,  1.3323e-02,  2.1831e-02, -8.9169e-02,\n",
       "                       -7.1374e-02, -9.5468e-04,  4.6757e-02, -1.0567e-01,  7.4792e-02,\n",
       "                        5.6071e-02,  5.5111e-02, -8.4583e-02,  4.1296e-02, -1.0943e-01,\n",
       "                       -5.4219e-02, -1.0082e-01, -3.4250e-02,  1.0125e-01,  8.6162e-02,\n",
       "                        6.7998e-02,  8.4893e-02, -8.1219e-02,  1.0101e-01, -8.3614e-02,\n",
       "                       -1.9703e-02, -1.0116e-01,  1.5267e-02, -4.3083e-03, -1.4077e-02,\n",
       "                        8.7525e-02,  3.4073e-03,  3.8058e-02, -8.4046e-02,  8.6071e-02,\n",
       "                        2.8757e-03,  7.1009e-02,  6.3257e-02, -1.1441e-01,  3.0978e-02,\n",
       "                       -7.0929e-02, -1.5347e-02,  5.9978e-03,  8.9475e-02,  8.1198e-03,\n",
       "                       -5.6484e-02, -8.5027e-02, -3.7390e-03, -1.0447e-01, -5.0707e-02,\n",
       "                       -7.7091e-02, -1.1171e-01,  9.0660e-04,  4.1167e-02,  8.7206e-02,\n",
       "                       -5.9956e-05,  2.8672e-02, -1.1846e-03,  6.5423e-02,  4.3564e-02,\n",
       "                       -3.5499e-02, -5.4924e-02, -4.9616e-02, -4.0730e-02, -9.8130e-02,\n",
       "                       -9.9082e-02, -5.5837e-02,  2.1177e-02,  1.1028e-01,  6.9856e-02,\n",
       "                        6.7762e-03,  9.8945e-02,  3.8868e-02, -5.3716e-02,  9.3252e-02,\n",
       "                        7.6670e-02,  2.0930e-02, -9.1577e-02, -5.2965e-03, -6.0980e-03,\n",
       "                        9.5721e-04, -8.5285e-02, -5.7880e-02, -4.3689e-02, -1.1588e-01,\n",
       "                       -1.8121e-02, -3.2506e-02, -9.7044e-03, -9.1521e-03, -1.0223e-01,\n",
       "                        1.0081e-01, -9.6181e-02, -7.4122e-03, -8.6344e-02,  5.6852e-02,\n",
       "                       -6.5288e-02, -7.7673e-02,  8.0201e-02, -9.2623e-02,  6.8165e-02,\n",
       "                        1.1081e-01,  2.2452e-03,  6.0290e-03,  9.8644e-02,  5.6807e-02,\n",
       "                       -3.3512e-02, -7.2924e-03, -4.2192e-02,  1.0363e-02,  2.7564e-02,\n",
       "                        2.4737e-02, -3.2584e-02,  8.7934e-02,  8.0683e-02,  1.6051e-03,\n",
       "                        6.6884e-02, -3.7562e-02, -1.0657e-01, -3.6412e-02, -1.0822e-01,\n",
       "                       -1.0987e-01,  9.2432e-02, -6.9479e-02, -9.0381e-02,  9.2522e-03,\n",
       "                       -3.4368e-02,  4.6240e-02, -9.4510e-02,  8.6926e-03, -7.0724e-02,\n",
       "                       -2.0457e-02,  1.1210e-02, -8.7480e-02, -4.4940e-02,  9.2552e-02,\n",
       "                       -5.2542e-02,  4.1119e-02,  6.8073e-02, -3.6389e-02, -5.1781e-02,\n",
       "                        1.0967e-01, -9.6539e-02, -9.6260e-02, -7.7626e-03,  4.4656e-02,\n",
       "                        4.8948e-02,  6.1086e-02, -6.6085e-03,  2.0136e-02, -1.0675e-01,\n",
       "                        1.1191e-01, -2.0587e-03,  1.0421e-01, -6.9866e-02,  9.4449e-02,\n",
       "                       -6.6881e-02, -3.5730e-02, -7.0480e-02,  2.2190e-02, -6.0579e-03,\n",
       "                        2.1793e-02, -2.8747e-02,  3.2983e-02, -5.0401e-02, -4.0499e-03,\n",
       "                       -3.3163e-02,  2.8341e-02,  7.4908e-03, -2.2848e-02, -7.1110e-02,\n",
       "                       -3.1127e-02,  7.1978e-03,  5.2847e-02,  1.1053e-01, -8.7591e-02,\n",
       "                        1.1093e-01,  8.8619e-02])),\n",
       "              ('GRUcell_list.0.weight_ih',\n",
       "               tensor([[-0.0325,  0.0135, -0.0149,  ...,  0.0278, -0.0270, -0.0424],\n",
       "                       [ 0.0397, -0.0432, -0.0402,  ...,  0.0045,  0.0311,  0.0355],\n",
       "                       [-0.0071, -0.0376, -0.0420,  ..., -0.0162,  0.0443,  0.0006],\n",
       "                       ...,\n",
       "                       [-0.0405,  0.0350,  0.0285,  ..., -0.0225,  0.0349, -0.0424],\n",
       "                       [-0.0220, -0.0189, -0.0118,  ...,  0.0437,  0.0408, -0.0311],\n",
       "                       [ 0.0054,  0.0080, -0.0253,  ..., -0.0132, -0.0060, -0.0159]])),\n",
       "              ('GRUcell_list.0.weight_hh',\n",
       "               tensor([[-0.0289,  0.0302,  0.0023,  ...,  0.0023,  0.0195,  0.0070],\n",
       "                       [ 0.0341,  0.0083, -0.0078,  ...,  0.0369,  0.0310,  0.0019],\n",
       "                       [-0.0427,  0.0218, -0.0173,  ...,  0.0394, -0.0118,  0.0231],\n",
       "                       ...,\n",
       "                       [-0.0265,  0.0363,  0.0125,  ...,  0.0035,  0.0332, -0.0059],\n",
       "                       [ 0.0021,  0.0228, -0.0421,  ..., -0.0203, -0.0383,  0.0012],\n",
       "                       [ 0.0356,  0.0158, -0.0080,  ...,  0.0392, -0.0108,  0.0205]])),\n",
       "              ('GRUcell_list.0.bias_ih',\n",
       "               tensor([-0.0263,  0.0400,  0.0083,  ...,  0.0431, -0.0436,  0.0007])),\n",
       "              ('GRUcell_list.0.bias_hh',\n",
       "               tensor([-0.0081, -0.0031, -0.0428,  ..., -0.0384, -0.0423, -0.0303])),\n",
       "              ('GRUcell_list.1.weight_ih',\n",
       "               tensor([[-0.0358,  0.0050, -0.0029,  ...,  0.0273, -0.0255,  0.0253],\n",
       "                       [ 0.0288, -0.0070,  0.0413,  ...,  0.0414, -0.0294,  0.0179],\n",
       "                       [-0.0230,  0.0185,  0.0398,  ...,  0.0004, -0.0201,  0.0137],\n",
       "                       ...,\n",
       "                       [-0.0262,  0.0029,  0.0327,  ...,  0.0396, -0.0287,  0.0216],\n",
       "                       [ 0.0169,  0.0235, -0.0032,  ..., -0.0147, -0.0122, -0.0374],\n",
       "                       [-0.0302, -0.0222,  0.0024,  ..., -0.0204,  0.0311, -0.0350]])),\n",
       "              ('GRUcell_list.1.weight_hh',\n",
       "               tensor([[-0.0173,  0.0107,  0.0016,  ...,  0.0361,  0.0215,  0.0089],\n",
       "                       [ 0.0138, -0.0090,  0.0371,  ..., -0.0039,  0.0217, -0.0002],\n",
       "                       [-0.0004,  0.0371,  0.0084,  ..., -0.0358,  0.0317,  0.0376],\n",
       "                       ...,\n",
       "                       [ 0.0241, -0.0255, -0.0426,  ...,  0.0126, -0.0152, -0.0071],\n",
       "                       [-0.0110, -0.0110,  0.0172,  ..., -0.0339, -0.0448,  0.0276],\n",
       "                       [-0.0193,  0.0142, -0.0187,  ..., -0.0220,  0.0353,  0.0003]])),\n",
       "              ('GRUcell_list.1.bias_ih',\n",
       "               tensor([ 0.0030,  0.0407,  0.0396,  ..., -0.0166, -0.0343,  0.0102])),\n",
       "              ('GRUcell_list.1.bias_hh',\n",
       "               tensor([-0.0001,  0.0097,  0.0215,  ..., -0.0304, -0.0101,  0.0057])),\n",
       "              ('fc1.weight',\n",
       "               tensor([[ 0.0293, -0.0012, -0.0205,  ...,  0.0007,  0.0193,  0.0112],\n",
       "                       [-0.0344,  0.0022,  0.0233,  ...,  0.0254,  0.0294,  0.0335],\n",
       "                       [-0.0132,  0.0131, -0.0325,  ...,  0.0301, -0.0405, -0.0238],\n",
       "                       ...,\n",
       "                       [ 0.0325, -0.0293, -0.0222,  ...,  0.0091, -0.0162,  0.0351],\n",
       "                       [ 0.0257, -0.0090,  0.0113,  ...,  0.0332, -0.0296, -0.0208],\n",
       "                       [ 0.0097, -0.0251, -0.0009,  ...,  0.0144,  0.0321, -0.0407]])),\n",
       "              ('fc1.bias',\n",
       "               tensor([-0.0121,  0.0247, -0.0386,  0.0398,  0.0281,  0.0313, -0.0345,  0.0054,\n",
       "                       -0.0014, -0.0344, -0.0110,  0.0132, -0.0371,  0.0168,  0.0137, -0.0045,\n",
       "                        0.0061, -0.0295, -0.0302, -0.0116,  0.0118, -0.0096,  0.0313, -0.0172,\n",
       "                        0.0136,  0.0146,  0.0179,  0.0299, -0.0426, -0.0263, -0.0031, -0.0433,\n",
       "                        0.0229,  0.0118, -0.0138,  0.0340, -0.0075,  0.0214, -0.0051, -0.0155,\n",
       "                       -0.0382, -0.0097, -0.0230, -0.0436, -0.0183, -0.0203,  0.0004,  0.0408,\n",
       "                        0.0411,  0.0161,  0.0057, -0.0314,  0.0331,  0.0385, -0.0168,  0.0406,\n",
       "                        0.0195,  0.0052,  0.0086,  0.0042,  0.0163,  0.0396, -0.0396,  0.0328,\n",
       "                        0.0235,  0.0186, -0.0390,  0.0349, -0.0265,  0.0434,  0.0388, -0.0267,\n",
       "                       -0.0148, -0.0244,  0.0411]))]),\n",
       " 'optimizer_state_dict': {'state': {0: {'step': 392,\n",
       "    'exp_avg': tensor([[ 7.0918e-08,  2.5454e-06, -3.7534e-07,  ...,  1.0237e-06,\n",
       "             -9.8026e-06,  1.5614e-06],\n",
       "            [ 1.1763e-06,  8.1290e-06, -7.2986e-07,  ...,  7.3795e-07,\n",
       "             -9.0869e-07, -1.4215e-05],\n",
       "            [ 4.5210e-07, -2.4839e-06, -1.2081e-06,  ..., -8.6187e-07,\n",
       "              2.5399e-06, -2.6786e-06],\n",
       "            ...,\n",
       "            [ 3.1124e-07,  1.6127e-05,  1.6295e-06,  ...,  3.6473e-07,\n",
       "             -6.8029e-06, -8.9757e-06],\n",
       "            [ 7.9769e-07, -2.5835e-06,  5.7677e-07,  ...,  1.1919e-06,\n",
       "             -1.3327e-06,  5.2516e-06],\n",
       "            [ 1.5084e-07, -8.2533e-06, -5.0608e-08,  ..., -3.7464e-06,\n",
       "              5.1649e-06,  5.1942e-06]]),\n",
       "    'exp_avg_sq': tensor([[2.2323e-07, 2.3646e-06, 1.6821e-06,  ..., 2.3799e-07, 1.3414e-06,\n",
       "             2.4996e-06],\n",
       "            [6.6201e-08, 4.2131e-05, 2.1792e-07,  ..., 3.1564e-07, 2.2751e-05,\n",
       "             1.5001e-05],\n",
       "            [1.8926e-07, 3.8396e-06, 5.3151e-07,  ..., 1.9544e-07, 2.0770e-06,\n",
       "             1.8397e-06],\n",
       "            ...,\n",
       "            [2.0215e-07, 3.4388e-05, 6.2965e-07,  ..., 3.7927e-07, 1.8465e-05,\n",
       "             1.2651e-05],\n",
       "            [6.7301e-07, 1.0602e-04, 6.3165e-06,  ..., 1.3671e-06, 5.9176e-05,\n",
       "             4.3771e-05],\n",
       "            [1.0567e-09, 3.4988e-06, 5.3032e-08,  ..., 2.0754e-08, 1.8670e-06,\n",
       "             1.2708e-06]])},\n",
       "   1: {'step': 392,\n",
       "    'exp_avg': tensor([-1.1134e-05, -2.1790e-05,  4.5889e-06,  3.5291e-05,  2.1572e-07,\n",
       "             4.9240e-06, -5.1730e-06,  1.4557e-05, -4.0165e-05, -8.1278e-06,\n",
       "             2.3964e-05,  2.2765e-06, -8.8184e-06,  1.0013e-05,  5.2977e-05,\n",
       "             1.6898e-05,  7.6908e-05, -4.2951e-05,  2.0827e-05,  2.8618e-07,\n",
       "             6.6065e-06,  3.1417e-05, -1.8384e-05,  9.0897e-07,  1.4680e-05,\n",
       "             8.8097e-06, -1.6292e-05, -1.5875e-05,  7.5579e-06, -2.9439e-06,\n",
       "             2.3197e-05,  5.7262e-05, -2.4175e-06,  4.2321e-05,  3.7651e-05,\n",
       "            -1.9335e-06, -1.9035e-05,  2.6683e-05,  1.8567e-05,  1.1365e-05,\n",
       "             8.4829e-06, -1.3217e-05, -1.5326e-05, -1.3038e-05, -3.1243e-06,\n",
       "            -9.3132e-06,  2.2110e-05, -6.8779e-07,  1.6620e-05,  2.2073e-06,\n",
       "             1.1323e-05,  1.1164e-05, -2.6897e-05, -3.8910e-06,  6.9024e-06,\n",
       "            -2.8172e-05, -2.1902e-05,  2.1317e-06,  5.7311e-06, -8.3416e-06,\n",
       "            -2.8047e-05,  3.7824e-06,  8.7641e-06, -1.1004e-05,  2.5657e-05,\n",
       "             2.4156e-06, -7.0177e-05, -2.1413e-05, -3.9537e-05, -2.0019e-05,\n",
       "             3.0971e-05, -3.1632e-05, -2.6549e-05,  3.9006e-06,  1.8030e-05,\n",
       "             7.6024e-06, -1.2780e-05, -8.9045e-06,  2.6666e-05,  9.9224e-06,\n",
       "             3.5203e-05, -1.2396e-05,  4.4037e-06, -5.8942e-06,  1.3565e-05,\n",
       "             1.4616e-06, -1.9390e-05,  1.8371e-05,  1.5584e-05,  2.7200e-05,\n",
       "            -4.5588e-05, -3.3362e-06,  9.9429e-06, -1.9121e-05,  9.4510e-06,\n",
       "            -1.7909e-05, -1.3854e-05,  2.4871e-05, -6.5565e-06,  1.0909e-05,\n",
       "             1.4736e-05,  1.1355e-05, -2.4492e-05,  1.8544e-05,  3.0520e-05,\n",
       "             2.1580e-05,  1.6189e-05, -1.5892e-05, -1.7577e-05, -4.7032e-07,\n",
       "             9.3818e-07, -3.9087e-05,  5.3297e-06,  1.9856e-06, -2.1370e-05,\n",
       "             7.7757e-06,  2.8449e-05,  1.3458e-05, -5.5847e-06,  5.0782e-06,\n",
       "             3.9314e-05, -2.4207e-05, -2.3653e-05, -2.8758e-05, -1.6871e-06,\n",
       "             1.5053e-05,  6.6795e-06, -1.2682e-05,  2.1742e-05, -1.6864e-05,\n",
       "            -2.2892e-05,  4.8138e-06,  7.2006e-05, -4.8073e-06,  3.8722e-05,\n",
       "             2.1328e-05,  3.2120e-05, -3.9218e-06,  2.3939e-05, -3.8591e-05,\n",
       "            -5.3723e-05, -1.8608e-05, -2.7538e-05,  9.5855e-06, -1.7779e-05,\n",
       "            -1.4777e-05, -1.8574e-05,  2.4087e-05,  1.2217e-05,  1.4000e-09,\n",
       "            -1.9827e-05, -1.5049e-05,  7.5473e-06,  2.7985e-05, -2.6904e-05,\n",
       "             7.7975e-06,  1.2320e-05,  1.6756e-05,  7.8765e-06, -5.0867e-06,\n",
       "            -1.3179e-05,  1.4730e-05,  3.0459e-05, -1.5270e-05,  1.0370e-06,\n",
       "            -2.8446e-05, -1.1620e-05,  1.4577e-05,  1.5621e-05,  2.7546e-05,\n",
       "            -2.2128e-05,  1.0293e-05,  1.5194e-05,  2.7532e-05, -1.8829e-05,\n",
       "            -3.4426e-05,  5.5743e-06,  1.4876e-05, -1.3570e-05,  5.3423e-06,\n",
       "             4.5929e-06,  1.0949e-05, -8.4004e-07, -2.9726e-05, -1.8058e-05,\n",
       "             2.9870e-05, -3.7710e-05,  2.7337e-05,  4.3939e-05, -1.3438e-06,\n",
       "            -3.9126e-08, -1.0264e-05,  1.7597e-05,  1.5314e-05, -2.5033e-05,\n",
       "             1.3267e-05,  2.6692e-09,  2.2837e-05,  3.1392e-05,  2.5952e-05,\n",
       "             1.3105e-05, -2.6815e-05,  3.3589e-05,  6.9796e-06, -2.6520e-05,\n",
       "            -4.7452e-05, -3.9865e-05,  2.8934e-05,  2.0418e-05, -3.9428e-05,\n",
       "            -3.0299e-05,  6.3237e-06, -8.7210e-06, -3.3700e-05,  2.2702e-05,\n",
       "            -2.1687e-05,  6.1263e-06, -8.0081e-06,  2.3343e-05,  5.3948e-05,\n",
       "             1.9499e-05, -1.4308e-06, -1.0643e-05, -6.9874e-06, -2.2549e-05,\n",
       "            -1.0204e-06, -3.3635e-07,  2.0998e-05, -6.1348e-06, -2.3205e-06,\n",
       "             7.7056e-05, -3.1201e-05, -1.5120e-05, -6.5302e-06, -1.3523e-05,\n",
       "            -2.0603e-05,  4.9103e-05,  3.5813e-05,  5.4877e-05, -2.7800e-06,\n",
       "            -1.5811e-05,  1.6489e-05, -9.4887e-06, -1.1546e-06,  2.4057e-05,\n",
       "             6.6420e-06, -2.3798e-07,  1.6282e-05, -2.1112e-05, -1.2782e-05,\n",
       "            -1.8063e-05,  1.4852e-05,  2.2993e-05, -7.4122e-07, -3.5002e-05,\n",
       "            -6.7953e-06,  6.7812e-07, -3.5068e-05, -4.9127e-05, -1.7750e-05,\n",
       "             5.7400e-06, -4.7940e-06,  2.1138e-05,  9.6445e-06,  2.1596e-05,\n",
       "            -2.6873e-05,  2.3826e-06, -2.5701e-05,  1.2236e-05, -8.1346e-06,\n",
       "             1.5621e-05, -6.1612e-06, -4.6758e-05, -1.3138e-05, -1.6643e-05,\n",
       "            -1.6812e-05,  2.0204e-05, -5.3004e-06, -3.4193e-05,  1.5424e-05,\n",
       "             7.8757e-06,  1.2929e-05, -1.3466e-05,  5.2691e-06, -1.6399e-05,\n",
       "             5.2524e-06, -4.3573e-06, -3.5787e-05,  2.2415e-05,  9.9165e-06,\n",
       "            -1.0289e-05,  1.6037e-05,  7.0336e-05, -2.0273e-06, -1.6088e-05,\n",
       "            -3.0370e-05, -1.8525e-05,  3.4539e-05, -2.3106e-05,  8.1649e-06,\n",
       "            -4.3141e-05,  3.5669e-05, -5.7278e-05, -4.0141e-06, -5.0344e-05,\n",
       "             2.5360e-05,  4.5176e-05, -3.9009e-06, -3.4879e-06,  2.8437e-05,\n",
       "             5.3335e-05, -7.6467e-06,  1.5427e-07,  1.2417e-06,  3.3203e-06,\n",
       "            -1.2972e-05,  2.1604e-05, -1.6975e-05,  5.5741e-05, -2.9176e-05,\n",
       "            -1.4648e-05, -7.9199e-06,  2.9994e-05,  5.2023e-06,  4.1337e-05,\n",
       "             1.2853e-05,  2.0223e-05,  4.4006e-06,  2.1187e-05, -8.7368e-06,\n",
       "             2.9161e-05, -3.3116e-05, -7.1985e-06, -2.0642e-05,  4.3970e-05,\n",
       "             2.9833e-05,  1.9665e-05,  9.6365e-07, -3.9387e-05,  4.7675e-06,\n",
       "             1.1577e-05, -3.5593e-06,  2.2173e-05, -1.1840e-06, -1.9523e-05,\n",
       "            -3.2046e-05, -3.5295e-05,  1.3845e-05,  2.3104e-05,  8.0402e-06,\n",
       "            -1.0622e-05, -4.3985e-05,  1.0967e-05, -1.5338e-05, -1.7717e-05,\n",
       "             7.0011e-06,  2.0563e-05, -4.3299e-05, -2.0219e-05, -1.3859e-06,\n",
       "             6.6585e-05,  9.9031e-06, -1.4502e-05,  1.8161e-05,  1.5752e-05,\n",
       "            -3.9938e-05, -1.5776e-05, -1.1558e-05, -3.1463e-05, -3.9441e-05,\n",
       "            -2.0055e-05, -1.7229e-07, -3.5931e-05, -2.5429e-06,  2.0165e-05,\n",
       "            -5.2248e-06, -2.1083e-05, -1.5701e-05,  2.9961e-05, -3.9203e-05,\n",
       "            -9.7836e-07,  3.2726e-05, -6.9997e-05,  2.6215e-05,  3.2445e-05,\n",
       "             2.2563e-05, -4.2105e-05, -5.5197e-06,  8.5341e-06,  2.0741e-05,\n",
       "            -2.9161e-05,  1.3979e-05, -1.2619e-06,  2.9637e-05, -4.8861e-05,\n",
       "             3.0304e-05,  5.3673e-06, -2.3626e-06,  2.2750e-05, -1.7118e-05,\n",
       "            -2.5878e-06,  2.3125e-05,  1.8576e-05,  4.4860e-05, -1.3406e-05,\n",
       "             1.2618e-05, -3.8996e-05, -2.1287e-05,  6.0248e-07, -1.3575e-05,\n",
       "            -1.8834e-05, -6.9099e-06,  1.1618e-05,  2.8331e-05,  2.3962e-05,\n",
       "            -1.3192e-06, -6.9665e-05,  2.1370e-07, -6.4325e-05,  1.7008e-05,\n",
       "            -3.4705e-05, -2.4179e-06, -4.6056e-05,  9.5203e-06, -1.6652e-05,\n",
       "             2.3886e-05,  2.3889e-05, -2.1753e-05,  1.9531e-06, -3.2741e-05,\n",
       "            -1.5172e-05,  1.2643e-05,  1.5716e-05, -2.9327e-05,  2.4717e-05,\n",
       "             2.4542e-05,  1.0192e-05, -4.3731e-05,  1.1484e-05, -3.9316e-05,\n",
       "             1.7182e-05, -1.0168e-05,  4.1774e-05, -5.5568e-06, -3.1596e-06,\n",
       "            -1.0114e-05,  2.1291e-05,  2.2047e-05,  3.3680e-05,  3.7609e-05,\n",
       "            -5.6896e-06, -1.7887e-05,  6.7676e-06,  3.6511e-05, -4.7745e-06,\n",
       "             1.7741e-05,  6.2753e-06,  3.8881e-05, -3.2768e-05,  5.7007e-06,\n",
       "            -1.5190e-08,  4.5048e-05, -3.4751e-05,  4.2447e-06,  4.7263e-05,\n",
       "             3.0231e-05, -3.7047e-06,  1.3933e-05, -4.0103e-05,  1.7131e-05,\n",
       "             1.3838e-05,  6.4011e-06,  1.8479e-05,  5.3187e-05,  2.5763e-05,\n",
       "            -1.8767e-05, -2.9784e-05, -1.6199e-05,  1.7788e-05,  2.5165e-05,\n",
       "            -2.6844e-05, -6.4547e-06,  2.9461e-05, -1.2737e-05, -3.7875e-05,\n",
       "             8.6281e-06,  1.1375e-05, -9.3708e-06, -3.0794e-05,  2.2010e-05,\n",
       "            -2.4796e-05,  8.1823e-06, -1.2371e-06, -3.5966e-06, -2.9948e-05,\n",
       "             2.6268e-05, -9.9631e-06, -1.4515e-05, -2.2618e-05,  1.9220e-05,\n",
       "            -4.7202e-06, -2.2581e-05, -1.1024e-05, -2.6538e-05, -2.3307e-05,\n",
       "            -4.0197e-06, -1.2455e-06,  2.4618e-05, -5.3518e-05, -3.8474e-05,\n",
       "             5.5585e-06,  2.1962e-05]),\n",
       "    'exp_avg_sq': tensor([2.0498e-05, 3.6870e-04, 3.3437e-05, 5.2982e-04, 2.6201e-04, 4.1428e-05,\n",
       "            1.0203e-03, 3.5868e-04, 4.8677e-04, 8.0340e-06, 2.7280e-05, 2.4509e-03,\n",
       "            1.6887e-04, 1.3517e-04, 2.5700e-05, 1.8773e-04, 2.4893e-04, 6.0566e-04,\n",
       "            2.4115e-04, 5.0950e-05, 5.3751e-04, 1.5408e-03, 1.7868e-03, 4.2848e-05,\n",
       "            1.7303e-08, 4.6780e-04, 2.6631e-06, 1.5405e-03, 8.2334e-04, 1.4947e-04,\n",
       "            8.0655e-04, 7.2006e-06, 2.0635e-04, 1.8707e-03, 8.3338e-05, 1.0843e-03,\n",
       "            1.7693e-05, 8.0439e-04, 6.4611e-04, 2.8099e-04, 8.8160e-04, 3.7947e-05,\n",
       "            1.2942e-03, 1.0805e-03, 1.5395e-04, 7.0395e-05, 1.2769e-04, 1.7770e-04,\n",
       "            3.0074e-06, 1.1643e-07, 3.1252e-04, 1.8571e-05, 8.2443e-05, 1.4335e-03,\n",
       "            1.6660e-05, 8.5454e-05, 1.9947e-04, 4.4827e-04, 8.2942e-04, 2.9370e-04,\n",
       "            7.7313e-04, 2.6236e-04, 4.6012e-04, 7.2771e-05, 1.5448e-04, 1.8493e-04,\n",
       "            1.6574e-04, 1.3564e-03, 2.2415e-03, 1.2788e-04, 1.5186e-04, 1.2347e-04,\n",
       "            1.2194e-04, 1.9169e-04, 8.4023e-06, 3.2709e-04, 1.4742e-04, 3.5833e-04,\n",
       "            1.5833e-04, 2.1614e-04, 1.3174e-03, 5.5288e-04, 1.0271e-04, 3.2909e-03,\n",
       "            1.0925e-03, 2.7700e-05, 2.0645e-03, 2.7594e-04, 1.4511e-04, 2.9715e-03,\n",
       "            1.1563e-04, 3.0976e-03, 9.8971e-05, 3.5288e-04, 4.8422e-04, 1.0067e-04,\n",
       "            1.3774e-04, 5.3091e-05, 5.7684e-04, 2.0261e-04, 5.8136e-04, 6.8412e-04,\n",
       "            2.8786e-05, 6.5738e-05, 9.5217e-04, 1.4457e-03, 9.5096e-05, 1.8678e-03,\n",
       "            8.6806e-05, 1.0701e-03, 1.8659e-04, 1.3245e-04, 7.8682e-07, 5.4461e-03,\n",
       "            5.8159e-04, 6.9859e-04, 1.5027e-03, 2.9996e-05, 1.1294e-03, 6.0803e-04,\n",
       "            5.2723e-04, 1.9100e-04, 7.0459e-06, 5.3411e-04, 1.6212e-03, 2.6579e-05,\n",
       "            2.8865e-04, 9.2236e-04, 4.4387e-05, 1.6852e-04, 2.3269e-04, 4.6378e-04,\n",
       "            1.3117e-04, 2.9917e-03, 8.8935e-05, 9.7916e-05, 2.7400e-04, 1.7623e-03,\n",
       "            3.8343e-06, 7.0678e-05, 9.2593e-04, 3.4883e-04, 8.5218e-04, 1.4190e-03,\n",
       "            8.4275e-05, 7.5913e-06, 2.0352e-04, 2.6745e-05, 1.1047e-03, 7.9396e-04,\n",
       "            1.7002e-03, 1.2042e-03, 4.3944e-05, 2.6340e-05, 4.8828e-03, 1.5587e-03,\n",
       "            2.7509e-03, 4.1244e-05, 1.1473e-04, 7.0599e-05, 7.0422e-04, 3.2682e-04,\n",
       "            3.8985e-04, 5.3104e-04, 2.8366e-04, 3.6976e-04, 6.9312e-04, 9.6952e-05,\n",
       "            2.8894e-04, 2.4084e-04, 8.7502e-05, 7.8317e-04, 5.9174e-05, 1.6507e-04,\n",
       "            3.3449e-04, 1.6247e-05, 2.6797e-04, 5.8843e-05, 2.9524e-06, 1.1511e-03,\n",
       "            3.4764e-04, 5.4891e-04, 3.0648e-04, 2.1506e-04, 4.2959e-05, 1.9559e-03,\n",
       "            7.6267e-05, 9.9518e-04, 8.7709e-05, 1.8856e-04, 3.1896e-06, 2.8837e-04,\n",
       "            2.2942e-07, 5.0913e-04, 2.3102e-05, 1.2938e-03, 8.9900e-04, 3.9100e-04,\n",
       "            9.9436e-04, 2.9661e-04, 3.2980e-04, 9.1706e-06, 3.9635e-04, 7.5743e-05,\n",
       "            1.5896e-03, 3.8157e-03, 1.2682e-03, 6.3960e-04, 6.0082e-05, 3.7571e-04,\n",
       "            4.4330e-04, 1.7760e-04, 2.5867e-03, 1.6733e-04, 2.1969e-03, 6.4903e-04,\n",
       "            7.4619e-04, 2.5025e-06, 6.1663e-04, 1.5743e-04, 1.5108e-05, 9.3530e-04,\n",
       "            1.3417e-04, 6.6227e-05, 1.7243e-05, 6.8565e-04, 5.9751e-05, 9.6666e-04,\n",
       "            1.7170e-04, 1.6139e-05, 8.0097e-04, 2.9528e-05, 5.1123e-05, 6.6524e-04,\n",
       "            4.1273e-04, 8.7188e-05, 7.7836e-06, 1.5120e-04, 1.3482e-05, 9.9155e-08,\n",
       "            2.1926e-05, 8.2199e-05, 2.2966e-05, 7.3349e-04, 1.2313e-04, 7.5603e-04,\n",
       "            1.6932e-03, 4.8197e-05, 5.9876e-05, 8.5978e-08, 9.2395e-04, 1.8154e-05,\n",
       "            1.0793e-03, 2.1137e-03, 2.3347e-03, 4.7111e-04, 1.3208e-05, 1.4664e-05,\n",
       "            4.5460e-05, 6.1525e-05, 2.3160e-04, 3.7162e-03, 5.9113e-04, 1.9635e-03,\n",
       "            2.8599e-05, 1.9349e-03, 1.1156e-03, 2.8333e-03, 1.7993e-04, 3.7235e-04,\n",
       "            2.3663e-04, 2.9860e-04, 7.6715e-04, 1.8025e-03, 7.5343e-05, 1.6046e-05,\n",
       "            6.8997e-04, 1.8401e-04, 2.0755e-03, 1.6884e-03, 2.1183e-03, 3.2169e-03,\n",
       "            5.4338e-04, 8.0278e-06, 2.9680e-03, 6.7732e-04, 3.7097e-05, 8.2217e-08,\n",
       "            8.6802e-04, 2.2222e-05, 2.1339e-05, 2.1128e-04, 1.6442e-04, 1.0096e-04,\n",
       "            1.3058e-03, 9.9734e-04, 1.9676e-03, 7.6444e-04, 1.8176e-04, 7.0187e-06,\n",
       "            1.8254e-04, 4.0566e-04, 4.2360e-04, 1.5151e-03, 1.9257e-05, 1.1286e-04,\n",
       "            6.9741e-04, 1.3350e-04, 1.1267e-04, 1.2056e-03, 2.0006e-03, 1.9012e-04,\n",
       "            7.9067e-05, 1.1543e-03, 4.0428e-08, 1.0017e-05, 6.1703e-04, 2.5658e-05,\n",
       "            3.6770e-03, 3.5091e-06, 1.4390e-04, 8.1762e-05, 8.8494e-05, 4.0995e-04,\n",
       "            6.5099e-04, 5.0003e-04, 4.0251e-04, 5.6577e-04, 4.5159e-03, 5.0004e-04,\n",
       "            1.2349e-04, 3.0028e-06, 2.0244e-06, 5.7134e-05, 5.1303e-04, 9.4770e-04,\n",
       "            8.5431e-04, 6.8836e-05, 1.8183e-03, 1.0730e-05, 1.2776e-03, 4.6328e-04,\n",
       "            1.5215e-03, 1.5701e-03, 1.7336e-05, 7.9996e-05, 1.0080e-04, 9.1258e-05,\n",
       "            2.0174e-05, 3.7304e-04, 5.5541e-05, 3.8499e-06, 5.2932e-04, 4.1822e-04,\n",
       "            1.1965e-04, 2.9716e-03, 9.2560e-04, 5.8101e-04, 1.3514e-03, 9.8484e-04,\n",
       "            4.0120e-04, 4.1052e-04, 1.0689e-03, 2.6533e-03, 7.6178e-04, 2.2307e-04,\n",
       "            1.0231e-03, 1.0471e-03, 2.0222e-03, 9.4167e-04, 7.5965e-06, 2.6879e-04,\n",
       "            5.2509e-06, 9.3151e-04, 7.2583e-04, 1.5910e-03, 3.5320e-04, 6.8428e-04,\n",
       "            1.8477e-04, 9.2026e-05, 1.6342e-03, 2.7520e-04, 2.8165e-05, 1.1000e-04,\n",
       "            1.7533e-03, 7.9540e-05, 6.0646e-06, 7.6716e-05, 1.8534e-03, 8.9160e-04,\n",
       "            3.0976e-05, 5.0396e-04, 4.2563e-04, 2.4918e-04, 8.4374e-04, 1.0353e-03,\n",
       "            1.6917e-04, 2.1797e-05, 7.6289e-04, 2.9243e-04, 3.5304e-07, 1.6608e-03,\n",
       "            7.1692e-04, 2.2059e-04, 6.0966e-04, 2.6429e-04, 1.3351e-03, 8.5726e-06,\n",
       "            3.6378e-06, 3.3384e-05, 3.1858e-04, 6.5455e-04, 6.7459e-05, 1.4594e-05,\n",
       "            1.4265e-03, 4.7788e-04, 1.3780e-03, 1.9802e-04, 1.5379e-07, 5.3333e-03,\n",
       "            1.1960e-03, 1.8293e-04, 3.9521e-04, 8.4689e-06, 1.8160e-04, 9.3038e-07,\n",
       "            4.8069e-04, 7.9642e-04, 1.2563e-03, 2.4933e-07, 1.8774e-05, 1.1038e-03,\n",
       "            6.4322e-04, 1.2766e-03, 3.4333e-05, 2.8106e-05, 1.7080e-03, 3.4130e-04,\n",
       "            4.1055e-06, 2.1503e-05, 2.7615e-04, 5.8320e-05, 1.1939e-03, 3.1977e-03,\n",
       "            1.0504e-04, 1.8399e-05, 1.5172e-04, 3.7263e-05, 2.5729e-06, 2.2516e-03,\n",
       "            2.6062e-05, 4.2008e-04, 1.7612e-06, 8.3315e-04, 2.7175e-04, 1.3947e-03,\n",
       "            2.0283e-04, 2.0329e-04, 2.8893e-05, 1.9877e-04, 3.1581e-05, 4.9702e-06,\n",
       "            2.6581e-05, 2.2814e-04, 2.9900e-03, 8.0565e-04, 3.9868e-07, 2.3719e-05,\n",
       "            1.8140e-04, 3.7861e-05, 3.1867e-07, 2.7753e-04, 4.6533e-04, 2.7931e-03,\n",
       "            1.1981e-05, 1.4121e-04, 7.2036e-04, 1.0082e-04, 2.6287e-03, 5.9888e-05,\n",
       "            1.8109e-04, 6.1396e-04, 1.2372e-05, 2.9610e-04, 5.1791e-04, 3.5475e-04,\n",
       "            2.8663e-03, 2.0535e-03, 1.1823e-03, 5.2589e-07, 9.1377e-07, 6.5463e-05,\n",
       "            1.8598e-04, 2.4765e-04, 3.4631e-05, 8.6577e-04, 3.0278e-04, 5.6588e-04,\n",
       "            4.2765e-04, 1.5976e-05, 4.2630e-04, 3.1233e-03, 7.9098e-04, 1.0833e-04,\n",
       "            1.6796e-03, 3.1218e-05, 1.9913e-03, 1.6798e-03, 1.4681e-04, 3.0045e-04,\n",
       "            9.3391e-04, 3.0512e-05])},\n",
       "   2: {'step': 392,\n",
       "    'exp_avg': tensor([[-7.6321e-08, -6.4319e-08, -9.7948e-08,  ...,  9.4564e-08,\n",
       "              8.6661e-09, -5.4306e-08],\n",
       "            [ 2.2912e-07,  1.3037e-07,  3.5395e-07,  ..., -2.8842e-07,\n",
       "             -9.5374e-08,  1.1604e-07],\n",
       "            [ 3.4769e-08,  8.7545e-10,  3.7554e-08,  ..., -4.5038e-08,\n",
       "             -1.4966e-08,  2.8440e-08],\n",
       "            ...,\n",
       "            [ 1.6489e-05,  8.5887e-06,  2.0707e-05,  ..., -1.9501e-05,\n",
       "             -8.2007e-06,  1.0102e-05],\n",
       "            [ 5.5639e-06,  5.4813e-06,  1.0184e-05,  ..., -6.2940e-06,\n",
       "             -1.6089e-06,  3.2780e-06],\n",
       "            [ 1.1334e-05,  1.1335e-05,  2.0187e-05,  ..., -1.8555e-05,\n",
       "             -4.4585e-06,  7.7434e-06]]),\n",
       "    'exp_avg_sq': tensor([[1.5522e-10, 8.4783e-11, 1.4274e-10,  ..., 4.7438e-11, 7.5110e-11,\n",
       "             1.1563e-11],\n",
       "            [2.1964e-10, 1.3411e-10, 5.1303e-10,  ..., 5.4238e-10, 3.3208e-12,\n",
       "             1.5830e-10],\n",
       "            [1.8284e-08, 1.1379e-08, 4.3181e-08,  ..., 4.5681e-08, 2.5252e-10,\n",
       "             1.3457e-08],\n",
       "            ...,\n",
       "            [3.5075e-05, 2.1508e-05, 8.2135e-05,  ..., 8.7025e-05, 4.7589e-07,\n",
       "             2.5422e-05],\n",
       "            [5.6706e-04, 3.5342e-04, 1.3399e-03,  ..., 1.4161e-03, 7.8552e-06,\n",
       "             4.1735e-04],\n",
       "            [1.4532e-06, 8.6991e-07, 3.3659e-06,  ..., 3.5693e-06, 1.9603e-08,\n",
       "             1.0320e-06]])},\n",
       "   3: {'step': 392,\n",
       "    'exp_avg': tensor([[-3.3270e-08,  2.2029e-08, -1.5000e-08,  ..., -4.2836e-08,\n",
       "              2.1916e-08,  2.4483e-09],\n",
       "            [ 2.8099e-08, -2.3482e-08,  5.0342e-08,  ...,  1.4144e-07,\n",
       "             -3.5065e-08, -7.7569e-09],\n",
       "            [-2.8783e-08,  1.4722e-08,  1.5370e-08,  ...,  1.8226e-08,\n",
       "              1.9459e-08, -1.3661e-08],\n",
       "            ...,\n",
       "            [-1.4734e-07, -9.3855e-07,  2.6016e-06,  ...,  3.1461e-06,\n",
       "             -1.5139e-06,  3.8339e-07],\n",
       "            [ 9.4855e-07, -1.6753e-06,  1.6757e-06,  ...,  1.2202e-06,\n",
       "             -1.0444e-06,  1.3314e-06],\n",
       "            [ 1.6091e-06, -2.4152e-06,  2.0779e-06,  ...,  3.4058e-06,\n",
       "             -2.4650e-06,  1.4660e-06]]),\n",
       "    'exp_avg_sq': tensor([[1.3133e-10, 5.6572e-12, 1.8835e-12,  ..., 1.5573e-11, 4.0993e-11,\n",
       "             9.4695e-11],\n",
       "            [3.5838e-11, 4.5302e-11, 5.4399e-12,  ..., 3.7865e-12, 3.8390e-12,\n",
       "             1.9999e-11],\n",
       "            [3.5333e-09, 4.5495e-09, 4.2319e-10,  ..., 3.5376e-10, 4.7732e-10,\n",
       "             2.2280e-09],\n",
       "            ...,\n",
       "            [1.2405e-06, 1.6207e-06, 1.6138e-07,  ..., 1.0469e-07, 1.1055e-07,\n",
       "             7.4879e-07],\n",
       "            [2.6772e-05, 3.5357e-05, 3.2641e-06,  ..., 2.1744e-06, 2.1104e-06,\n",
       "             1.6996e-05],\n",
       "            [5.7887e-08, 7.4175e-08, 9.7405e-09,  ..., 6.5323e-09, 7.0681e-09,\n",
       "             3.0889e-08]])},\n",
       "   4: {'step': 392,\n",
       "    'exp_avg': tensor([-2.9933e-07,  8.8794e-07,  1.4646e-07,  ...,  5.3743e-05,\n",
       "             2.4185e-05,  4.3953e-05]),\n",
       "    'exp_avg_sq': tensor([5.7539e-10, 3.5467e-09, 3.0119e-07,  ..., 5.6930e-04, 9.3469e-03,\n",
       "            2.3125e-05])},\n",
       "   5: {'step': 392,\n",
       "    'exp_avg': tensor([-2.9933e-07,  8.8794e-07,  1.4646e-07,  ...,  2.2036e-05,\n",
       "             1.0725e-05,  2.0572e-05]),\n",
       "    'exp_avg_sq': tensor([5.7539e-10, 3.5467e-09, 3.0119e-07,  ..., 1.1385e-04, 2.3945e-03,\n",
       "            6.0518e-06])},\n",
       "   6: {'step': 392,\n",
       "    'exp_avg': tensor([[ 1.3962e-07, -1.8142e-07,  1.7296e-07,  ...,  2.3090e-07,\n",
       "             -1.3995e-07,  5.4306e-08],\n",
       "            [-6.9247e-08,  5.8144e-08, -3.9027e-08,  ..., -5.2360e-08,\n",
       "             -9.2488e-10, -2.1465e-08],\n",
       "            [ 3.8551e-09,  1.5220e-08, -6.7089e-08,  ..., -1.9614e-08,\n",
       "              2.9922e-08, -6.3552e-08],\n",
       "            ...,\n",
       "            [-1.4865e-06,  3.4035e-06, -3.7817e-06,  ..., -5.3669e-06,\n",
       "              3.3555e-06, -3.6810e-06],\n",
       "            [ 1.9101e-06,  3.0794e-06, -7.0093e-06,  ..., -1.1334e-05,\n",
       "              4.3378e-06, -3.9142e-06],\n",
       "            [ 7.3560e-06, -1.2093e-05,  1.4957e-05,  ...,  2.1363e-05,\n",
       "             -1.2506e-05,  3.5889e-06]]),\n",
       "    'exp_avg_sq': tensor([[1.4751e-09, 1.9600e-09, 1.7473e-10,  ..., 1.7308e-10, 1.8588e-10,\n",
       "             1.0447e-09],\n",
       "            [5.5503e-08, 7.3825e-08, 6.6468e-09,  ..., 4.6141e-09, 3.9460e-09,\n",
       "             3.7071e-08],\n",
       "            [8.5666e-12, 1.1208e-11, 1.3192e-12,  ..., 1.1188e-12, 7.8386e-13,\n",
       "             5.3234e-12],\n",
       "            ...,\n",
       "            [2.7320e-05, 3.6434e-05, 3.1824e-06,  ..., 2.1842e-06, 1.8558e-06,\n",
       "             1.8326e-05],\n",
       "            [3.3002e-05, 4.4079e-05, 3.8316e-06,  ..., 2.6407e-06, 2.0758e-06,\n",
       "             2.2629e-05],\n",
       "            [2.3662e-06, 3.1556e-06, 2.8203e-07,  ..., 2.1454e-07, 1.8171e-07,\n",
       "             1.6294e-06]])},\n",
       "   7: {'step': 392,\n",
       "    'exp_avg': tensor([[-8.0730e-08, -2.7825e-07, -5.3673e-08,  ..., -3.3183e-08,\n",
       "              4.8338e-08, -1.7538e-07],\n",
       "            [ 4.8850e-08,  6.8628e-08, -2.2215e-08,  ..., -3.7433e-08,\n",
       "              2.6908e-08,  1.0146e-07],\n",
       "            [-5.6954e-09,  4.4002e-08,  5.3478e-08,  ...,  3.9879e-08,\n",
       "             -4.4037e-08,  4.2631e-09],\n",
       "            ...,\n",
       "            [ 1.8702e-07,  2.4704e-06,  6.4095e-07,  ...,  6.1921e-07,\n",
       "              3.5082e-07,  1.7467e-06],\n",
       "            [ 7.8238e-07,  4.8134e-06,  3.2846e-06,  ...,  1.5751e-06,\n",
       "             -1.8410e-06,  2.1465e-06],\n",
       "            [-3.0400e-06, -1.0965e-05, -5.5260e-06,  ..., -1.6026e-06,\n",
       "              1.2790e-06, -6.7388e-06]]),\n",
       "    'exp_avg_sq': tensor([[2.5120e-11, 3.4016e-10, 1.2819e-09,  ..., 8.4543e-10, 7.8238e-12,\n",
       "             3.3875e-10],\n",
       "            [2.5574e-10, 1.2883e-08, 4.7688e-08,  ..., 2.6150e-08, 2.2847e-10,\n",
       "             1.0344e-08],\n",
       "            [1.3208e-13, 2.7355e-12, 6.3236e-12,  ..., 3.5203e-12, 2.2949e-13,\n",
       "             1.4844e-12],\n",
       "            ...,\n",
       "            [2.1521e-08, 1.3943e-06, 5.2698e-06,  ..., 2.8577e-06, 2.0959e-08,\n",
       "             1.1354e-06],\n",
       "            [2.7605e-08, 1.9105e-06, 7.0670e-06,  ..., 3.8182e-06, 2.5631e-08,\n",
       "             1.5396e-06],\n",
       "            [5.0096e-09, 1.2665e-07, 4.6545e-07,  ..., 2.7104e-07, 2.4455e-09,\n",
       "             1.0928e-07]])},\n",
       "   8: {'step': 392,\n",
       "    'exp_avg': tensor([ 1.4843e-06, -1.5265e-07, -4.6143e-07,  ..., -3.8834e-05,\n",
       "            -7.1044e-05,  1.2695e-04]),\n",
       "    'exp_avg_sq': tensor([1.3002e-07, 4.9240e-06, 7.0288e-10,  ..., 2.4130e-03, 2.9330e-03,\n",
       "            2.1078e-04])},\n",
       "   9: {'step': 392,\n",
       "    'exp_avg': tensor([ 1.4843e-06, -1.5265e-07, -4.6143e-07,  ..., -1.7974e-05,\n",
       "            -3.8066e-05,  6.1409e-05]),\n",
       "    'exp_avg_sq': tensor([1.3002e-07, 4.9240e-06, 7.0288e-10,  ..., 5.3139e-04, 6.9885e-04,\n",
       "            4.7326e-05])},\n",
       "   10: {'step': 392,\n",
       "    'exp_avg': tensor([[ 6.5019e-06,  1.4662e-05, -8.6618e-06,  ..., -1.4331e-07,\n",
       "              3.2407e-06,  1.7278e-05],\n",
       "            [-8.4851e-07,  1.5367e-05,  1.9424e-05,  ..., -9.8178e-07,\n",
       "             -2.1902e-06,  7.4556e-06],\n",
       "            [ 1.9186e-05,  4.9641e-05,  1.2940e-05,  ...,  1.3387e-05,\n",
       "             -9.3094e-06,  3.1682e-05],\n",
       "            ...,\n",
       "            [ 5.6095e-06,  1.6052e-05, -1.5564e-05,  ...,  6.0832e-06,\n",
       "             -1.2835e-06,  1.4858e-05],\n",
       "            [ 2.1569e-05,  6.4255e-05,  2.6907e-05,  ...,  7.8571e-06,\n",
       "             -1.0766e-05,  4.1016e-05],\n",
       "            [ 1.2995e-05,  5.6077e-05,  1.6213e-05,  ...,  1.8755e-05,\n",
       "             -7.7972e-06,  3.2217e-05]]),\n",
       "    'exp_avg_sq': tensor([[3.7990e-06, 2.5967e-04, 9.3426e-04,  ..., 5.0194e-04, 3.6175e-06,\n",
       "             2.0258e-04],\n",
       "            [6.7763e-06, 4.8481e-04, 1.7538e-03,  ..., 9.4052e-04, 6.2382e-06,\n",
       "             3.7961e-04],\n",
       "            [1.7814e-06, 1.2643e-04, 4.5619e-04,  ..., 2.4482e-04, 1.6896e-06,\n",
       "             9.8804e-05],\n",
       "            ...,\n",
       "            [3.4456e-06, 2.3335e-04, 8.3964e-04,  ..., 4.5097e-04, 3.2540e-06,\n",
       "             1.8209e-04],\n",
       "            [6.2449e-06, 4.4719e-04, 1.6190e-03,  ..., 8.6775e-04, 5.6926e-06,\n",
       "             3.5035e-04],\n",
       "            [1.8244e-06, 1.2880e-04, 4.6451e-04,  ..., 2.4932e-04, 1.7291e-06,\n",
       "             1.0062e-04]])},\n",
       "   11: {'step': 392,\n",
       "    'exp_avg': tensor([-1.1585e-04, -5.8190e-05, -3.4914e-04,  5.7484e-05,  1.8949e-04,\n",
       "            -3.3047e-04, -8.4878e-07, -6.5735e-05, -4.0806e-04,  1.1658e-05,\n",
       "            -4.8260e-05, -2.8099e-04, -4.8130e-05, -1.5958e-04, -4.4482e-04,\n",
       "            -1.9252e-04, -4.3621e-05, -6.3472e-04, -5.7734e-07,  3.8287e-05,\n",
       "            -2.5998e-04, -2.6425e-04,  3.5430e-04, -5.6432e-04, -3.2405e-04,\n",
       "             2.3292e-04, -8.0122e-04, -9.2664e-05, -2.1706e-04, -2.2499e-04,\n",
       "            -4.1513e-04, -1.2112e-05, -3.9678e-04, -2.2093e-04,  1.7410e-04,\n",
       "            -7.9082e-04, -1.0452e-04, -1.6319e-04, -1.2988e-04, -2.0624e-06,\n",
       "            -3.4073e-04, -1.9336e-04, -8.8817e-06, -9.7485e-05, -2.4747e-04,\n",
       "            -1.7837e-04, -2.8098e-04, -1.4457e-05, -6.8461e-05, -1.4921e-04,\n",
       "            -6.3440e-05,  7.4845e-05, -1.5317e-04, -3.5848e-04, -1.3800e-04,\n",
       "            -2.8893e-04, -3.2018e-04,  1.4105e-04,  2.2758e-04, -5.1840e-04,\n",
       "            -2.6400e-04,  7.5767e-05, -1.2034e-04, -1.8815e-04,  4.6892e-04,\n",
       "            -1.0293e-03, -1.4158e-04, -3.4215e-04, -2.4709e-04, -1.2611e-04,\n",
       "            -3.4153e-04, -1.9822e-04, -1.0853e-04, -3.6333e-04, -3.6812e-04]),\n",
       "    'exp_avg_sq': tensor([0.0948, 0.1779, 0.0463, 0.0954, 0.1945, 0.0265, 0.1060, 0.1733, 0.0335,\n",
       "            0.0871, 0.1807, 0.0340, 0.0827, 0.1813, 0.0400, 0.0924, 0.1921, 0.0449,\n",
       "            0.1029, 0.1609, 0.0442, 0.0781, 0.2001, 0.0414, 0.0938, 0.1730, 0.0363,\n",
       "            0.0828, 0.1733, 0.0441, 0.0905, 0.1888, 0.0402, 0.1203, 0.1901, 0.0381,\n",
       "            0.0841, 0.1519, 0.0397, 0.0884, 0.2239, 0.0640, 0.0717, 0.1347, 0.0449,\n",
       "            0.1020, 0.2166, 0.0549, 0.0801, 0.1850, 0.0517, 0.0929, 0.1792, 0.0389,\n",
       "            0.0875, 0.1838, 0.0370, 0.1124, 0.1946, 0.0297, 0.1043, 0.2054, 0.0518,\n",
       "            0.0897, 0.1714, 0.0662, 0.0813, 0.1702, 0.0348, 0.0930, 0.1869, 0.0519,\n",
       "            0.0852, 0.1643, 0.0471])}},\n",
       "  'param_groups': [{'lr': 0.0001,\n",
       "    'betas': (0.9, 0.999),\n",
       "    'eps': 1e-08,\n",
       "    'weight_decay': 0,\n",
       "    'amsgrad': False,\n",
       "    'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]},\n",
       " 'loss': tensor(0.0036, requires_grad=True)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "958fc388",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for PoseGRU_inputFC2:\n\tMissing key(s) in state_dict: \"input_fc.weight\", \"input_fc.bias\", \"GRUcell_list.0.weight_ih\", \"GRUcell_list.0.weight_hh\", \"GRUcell_list.0.bias_ih\", \"GRUcell_list.0.bias_hh\", \"GRUcell_list.1.weight_ih\", \"GRUcell_list.1.weight_hh\", \"GRUcell_list.1.bias_ih\", \"GRUcell_list.1.bias_hh\", \"fc1.weight\", \"fc1.bias\". \n\tUnexpected key(s) in state_dict: \"epoch\", \"batch_num\", \"model_state_dict\", \"optimizer_state_dict\", \"loss\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-a1656b44a292>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mgru\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPoseGRU_inputFC2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgru\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\torch3d\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1481\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1482\u001b[1;33m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[0;32m   1483\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0;32m   1484\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for PoseGRU_inputFC2:\n\tMissing key(s) in state_dict: \"input_fc.weight\", \"input_fc.bias\", \"GRUcell_list.0.weight_ih\", \"GRUcell_list.0.weight_hh\", \"GRUcell_list.0.bias_ih\", \"GRUcell_list.0.bias_hh\", \"GRUcell_list.1.weight_ih\", \"GRUcell_list.1.weight_hh\", \"GRUcell_list.1.bias_ih\", \"GRUcell_list.1.bias_hh\", \"fc1.weight\", \"fc1.bias\". \n\tUnexpected key(s) in state_dict: \"epoch\", \"batch_num\", \"model_state_dict\", \"optimizer_state_dict\", \"loss\". "
     ]
    }
   ],
   "source": [
    "gru = PoseGRU_inputFC2(input_size=(25,3))\n",
    "gru.load_state_dict(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06e4b77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx, in_joints, pred_joints = pd.__getitem__(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b23907d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 25, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_joints.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b36a17c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 25, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_joints.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd05df57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0934, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(in_joints[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1179a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(-0.0895, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0895, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0878, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0915, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0925, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0924, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0904, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0901, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0888, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0934, grad_fn=<MeanBackward0>)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[torch.mean(x) for x in in_joints]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2bbed5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
